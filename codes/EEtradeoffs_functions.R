## Replication code for "Understanding Managers' Trade-offs between Exploration and Exploitation"
# Author: Alina Ferecatu and Arnaud De Bruyn
# Date: April 2021

set.seed(123456)
## Basic functions ----
logsumexp <- function(x) {
  y = max(x)
  y + log(sum(exp(x - y)))
}
softmax <- function(x) {
  exp(x - logsumexp(x))
}

inv_logit <- function(logit) {
  exp(logit) / (1 + exp(logit))
}


get_label_swap <- function(...) {
  dots<-list(...)
  function(variable, value) {
    if(variable %in% names(dots)) {
      swaps <- dots[[variable]]
      vals <- as.character(value)
      lapply(vals, function(v) {if(v %in% names(swaps)) swaps[[v]] else v })
    } else {
      label_value(variable, value)
    }
  }
}

## Optimal path funtions ----

Phi=function(s)
{       if(s<=0.2) {result=sqrt(s/2)
}else if(s>0.2 & s<=1) {result=0.49-0.11/sqrt(s)
}else if(s>1 & s<=5) {result=0.63-0.26/sqrt(s)
}else if(s>5 & s<=15) {result=0.77-0.58/sqrt(s)
}else {result=sqrt(2*log(s)-log(log(s))-log(16*pi))}
  return(result)
}

### Stan functions for model estimation ----
#* EEI/EWA full model ----
hmme_eei_ewa_mixed="
functions {
vector normalize(vector x) {
return x / sum(x);
}
}

data {
int<lower=1> N; // Observations
int<lower=1> N_arms; // Alternatives
int<lower=1> H; // Players
int<lower=1> K; // number of hidden states
int<lower=1> D;
int<lower=1, upper=N_arms> y[N]; // Choice Indicator
int T[N]; // Rounds
int<lower=0, upper=1> lastT[N];  // vector for the time series per individual
int<lower=1> ID[N];              // vector of individual index
vector[N_arms] prior; // prior knowledge
real X[N]; // stacked observations
simplex[K] pi0;
int z[K];
real<lower=0, upper=10> N0;
int <lower=1> ndem;
matrix[H, ndem] u;
}

transformed data {
row_vector[D] zeros;
int<lower=1> nvar_ind;
int<lower=1> nvar_baseline;
int<lower=1> nvar_cov;

zeros = rep_row_vector(0, D);
nvar_ind=(K-1)*K+3;
nvar_baseline=(K-1)*K;
nvar_cov=K*(K-1)*(D-1);
}

parameters {
real lambda_explore_unt;
matrix[nvar_ind, H] alpha; // nvar*H parameter matrix
matrix[ndem, nvar_ind] gamma; // delta
cholesky_factor_corr[nvar_ind] L_Omega; // Vbeta- prior correlation
vector<lower=0>[nvar_ind] tau;
vector[nvar_cov] betaD; 
}

transformed parameters {
vector[K] unalpha_tk[N];
vector[K] unalpha_Tkn[H];
vector[N_arms] empb[K];

vector[N_arms] W_Average;
vector[N_arms] ew;
real ew1;

row_vector[D] XD;
real gl;
real Xsum;
real Xmean;

matrix[K, D] beta[K, H];
vector[(K-1)] tempV;
matrix[(K-1), D] tempM;

real<lower=0, upper=1> lambda_explore;
real<lower=0, upper=1> lambda_exploit[H]; // delta
real<lower=0, upper=1> rho[H]; // delta
real<lower=0, upper=1> phi[H]; // delta

matrix[H, nvar_ind] delta;
matrix[H, nvar_ind] Vdelta_reparametrized;

Vdelta_reparametrized = (diag_pre_multiply(tau, L_Omega)*alpha)';
delta=u*gamma+Vdelta_reparametrized;

lambda_explore=inv_logit(lambda_explore_unt);

for (h in 1:H)
{
  lambda_exploit[h]=inv_logit(lambda_explore_unt+exp(delta[h,7]));
  rho[h]=inv_logit(delta[h,8]);
  phi[h]=inv_logit(delta[h,9]);
  
  for (i in 1:K)
  {
  for(l in 1:(K-1))
  {tempV[l]=delta[h,((i-1)*(K-1)+l)];}
  //matrix is filled by column;
  tempM = append_col(tempV, [betaD[(i-1)*(K-1)+1], betaD[(i-1)*(K-1)+2]]');
  beta[i, h]= append_row(tempM, zeros);
  }
}

// Transition probabilities
for (n in 1:N)
{ // Forwards algorithm log p(z_t = j | x_{1:t})
real accumulator[K];

// at T=1
if(T[n]==1){
ew=rep_vector(N0, N_arms);
W_Average=prior;
Xmean=prior[1];
Xsum=prior[1];

empb[1]=[0.333333, 0.333333, 0.333334]';
for(j in 2:K)
empb[j]=rep_vector(0.000001, N_arms);

for (j in 1:K) {
// everyone starts in state 1;
unalpha_tk[n][j] =log(pi0[j]) + log(empb[j, y[n]]);
}

//gl=prior[1]/10;//(X[n]>prior[1] ? 0 : 1);
// running average per arm;
gl=(X[n]>Xmean ? 0 : 1);
Xsum=Xsum+X[n];
Xmean=Xsum/(T[n]+1);

}else{

//gain/ loss: it's a raw vector;
XD=[1, gl];

ew1=ew[y[n-1]];
ew[y[n-1]]= rho[ID[n]]*ew[y[n-1]]+1;
W_Average[y[n-1]]=(phi[ID[n]]*ew1*W_Average[y[n-1]]+X[n-1])/ew[y[n-1]];

// empb[1]=log([0.333333, 0.333333, 0.333334]');

for(arm in 1:N_arms){
//State 1 - random: keep empb[1];
empb[1, arm]=categorical_logit_lpmf(arm|lambda_explore*W_Average);
// State 2 - exploitation;
empb[2, arm]=categorical_logit_lpmf(arm|lambda_exploit[ID[n]]*W_Average);
// State 3 - inertia;
empb[3, arm]=log(arm==y[n-1] ? 0.99995 : 0.000025);}

for (j in 1:K) { // j = current (t)
for (i in 1:K) { // i = previous (t-1)
// Murphy (2012) Eq. 17.48
// belief state + transition prob + local evidence at t
accumulator[i] = unalpha_tk[n-1, i]+categorical_logit_lpmf(z[j]|to_vector(XD*beta[i,ID[n]]')) + empb[j, y[n]];
}
unalpha_tk[n, j] = log_sum_exp(accumulator);
}

gl=(X[n]>Xmean ? 0 : 1);
Xsum=Xsum+X[n];
Xmean=Xsum/(T[n]+1);
}

if(lastT[n]==1)
{unalpha_Tkn[ID[n]]=unalpha_tk[n];}
} // Forward

}

model {
lambda_explore_unt ~ normal(0,1);
to_vector(gamma) ~ normal(0, 1);
to_vector(betaD)~normal(0,1);
L_Omega~lkj_corr_cholesky(2);
tau~exponential(1);
to_vector(alpha)~normal(0, 1);

for (i in 1:H)
target += log_sum_exp(unalpha_Tkn[i]); // Note: update based only on last unalpha_tk
}

generated quantities{
vector[K] alpha_tk[N];
corr_matrix[nvar_ind] Omega;
matrix<lower=0, upper=1>[K, N_arms] empb_n[N];  // choice probability: pb of 1 or 0, given state, at each obs.
real log_lik[H];                    // lk based on filtered probs
matrix[K, N_arms] empbg;
vector[N_arms] W_Averageg;
vector[N_arms] ewg;
real ew1g;
  
Omega = L_Omega * L_Omega';

{ // Forward algortihm
for (n in 1:N)
alpha_tk[n] = softmax(unalpha_tk[n]);
} // Forward

for (i in 1:H)
log_lik[i]=log_sum_exp(unalpha_Tkn[i]);

{ // local section
for (n in 1:N){
  
if(T[n]==1){

ewg=rep_vector(N0, N_arms);
W_Averageg=prior;

empbg[1]=[0.333333, 0.333333, 0.333334];

for(j in 2:K)
empbg[j]=rep_row_vector(0.000001, N_arms);

empb_n[n]=empbg;

 }else{

ew1g=ewg[y[n-1]];
ewg[y[n-1]]= rho[ID[n]]*ewg[y[n-1]]+1;
W_Averageg[y[n-1]]=(phi[ID[n]]*ew1g*W_Averageg[y[n-1]]+X[n-1])/ewg[y[n-1]];

for (arm in 1:N_arms){
  //State 1 - random: keep empb[1];
    empbg[1, arm]=exp(categorical_logit_lpmf(arm|lambda_explore*W_Averageg));
    // State 2 - exploitation;
    empbg[2, arm]=exp(categorical_logit_lpmf(arm|lambda_exploit[ID[n]]*W_Averageg));
    // State 3 - inertia;
    empbg[3, arm]=(arm==y[n-1] ? 0.99995 : 0.000025);
}

empb_n[n]= empbg;
}
}
}
}
"

#* EEI/EWA model code for Experiment 2 with informative priors ----
hmme_eei_ewa_mixed_infPriors="
functions {
vector normalize(vector x) {
return x / sum(x);
}
}

data {
int<lower=1> N; // Observations
int<lower=1> N_arms; // Alternatives
int<lower=1> H; // Players
int<lower=1> K; // number of hidden states
int<lower=1> D;
int<lower=1, upper=N_arms> y[N]; // Choice Indicator
int T[N]; // Rounds
int<lower=0, upper=1> lastT[N];  // vector for the time series per individual
int<lower=1> ID[N];              // vector of individual index
vector[N_arms] prior; // prior knowledge
real X[N]; // stacked observations
simplex[K] pi0;
int z[K];
real<lower=0, upper=10> N0;
int <lower=1> ndem;
matrix[H, ndem] u;
int<lower=1> nvar_ind;
int<lower=1> nvar_baseline;
int<lower=1> nvar_cov;
int<lower=1> dim_gamma_prior;
real lambda_prior_mean;
real lambda_prior_sd;
vector[dim_gamma_prior] gamma_prior_mean;
cov_matrix[dim_gamma_prior] gamma_prior_sd;
vector[nvar_cov] betaD_prior_mean;
cov_matrix[nvar_cov] betaD_prior_sd;
}

transformed data {
row_vector[D] zeros;
zeros = rep_row_vector(0, D);
}

parameters {
real lambda_explore_unt;
matrix[nvar_ind, H] alpha; // nvar*H parameter matrix
matrix[ndem, nvar_ind] gamma; // delta
cholesky_factor_corr[nvar_ind] L_Omega; // Vbeta- prior correlation
vector<lower=0>[nvar_ind] tau;
vector[nvar_cov] betaD; 
}

transformed parameters {
vector[K] unalpha_tk[N];
vector[K] unalpha_Tkn[H];
vector[N_arms] empb[K];

vector[N_arms] W_Average;
vector[N_arms] ew;
real ew1;

row_vector[D] XD;
real gl;
real Xsum;
real Xmean;

matrix[K, D] beta[K, H];
vector[(K-1)] tempV;
matrix[(K-1), D] tempM;

real<lower=0, upper=1> lambda_explore;
real<lower=0, upper=1> lambda_exploit[H]; // delta
real<lower=0, upper=1> rho[H]; // delta
real<lower=0, upper=1> phi[H]; // delta

matrix[H, nvar_ind] delta;
matrix[H, nvar_ind] Vdelta_reparametrized;

Vdelta_reparametrized = (diag_pre_multiply(tau, L_Omega)*alpha)';
delta=u*gamma+Vdelta_reparametrized;

lambda_explore=inv_logit(lambda_explore_unt);

for (h in 1:H)
{
  lambda_exploit[h]=inv_logit(lambda_explore_unt+exp(delta[h,7]));
  rho[h]=inv_logit(delta[h,8]);
  phi[h]=inv_logit(delta[h,9]);
  
  for (i in 1:K)
  {
  for(l in 1:(K-1))
  {tempV[l]=delta[h,((i-1)*(K-1)+l)];}
  //matrix is filled by column;
  tempM = append_col(tempV, [betaD[(i-1)*(K-1)+1], betaD[(i-1)*(K-1)+2]]');
  beta[i, h]= append_row(tempM, zeros);
  }
}
//print(beta);

// Transition probabilities
for (n in 1:N)
{ // Forwards algorithm log p(z_t = j | x_{1:t})
real accumulator[K];

// at T=1
if(T[n]==1){
ew=rep_vector(N0, N_arms);
W_Average=prior;
Xmean=prior[1];
Xsum=prior[1];

empb[1]=[0.333333, 0.333333, 0.333334]';
for(j in 2:K)
empb[j]=rep_vector(0.000001, N_arms);

for (j in 1:K) {
// everyone starts in state 1;
unalpha_tk[n][j] =log(pi0[j]) + log(empb[j, y[n]]);
}

//gl=prior[1]/10;//(X[n]>prior[1] ? 0 : 1);
// running average per arm;
gl=(X[n]>Xmean ? 0 : 1);
Xsum=Xsum+X[n];
Xmean=Xsum/(T[n]+1);

}else{

//gain/ loss: it's a raw vector;
XD=[1, gl];

ew1=ew[y[n-1]];
ew[y[n-1]]= rho[ID[n]]*ew[y[n-1]]+1;
W_Average[y[n-1]]=(phi[ID[n]]*ew1*W_Average[y[n-1]]+X[n-1])/ew[y[n-1]];

// empb[1]=log([0.333333, 0.333333, 0.333334]');

for(arm in 1:N_arms){
//State 1 - random: keep empb[1];
empb[1, arm]=categorical_logit_lpmf(arm|lambda_explore*W_Average);
// State 2 - exploitation;
empb[2, arm]=categorical_logit_lpmf(arm|lambda_exploit[ID[n]]*W_Average);
// State 3 - inertia;
empb[3, arm]=log(arm==y[n-1] ? 0.99995 : 0.000025);}

for (j in 1:K) { // j = current (t)
for (i in 1:K) { // i = previous (t-1)
// Murphy (2012) Eq. 17.48
// belief state + transition prob + local evidence at t
accumulator[i] = unalpha_tk[n-1, i]+categorical_logit_lpmf(z[j]|to_vector(XD*beta[i,ID[n]]')) + empb[j, y[n]];
}
unalpha_tk[n, j] = log_sum_exp(accumulator);
}

gl=(X[n]>Xmean ? 0 : 1);
Xsum=Xsum+X[n];
Xmean=Xsum/(T[n]+1);
}

if(lastT[n]==1)
{unalpha_Tkn[ID[n]]=unalpha_tk[n];}
} // Forward

}

model {
lambda_explore_unt ~ normal(lambda_prior_mean, lambda_prior_sd);
to_vector(gamma) ~ multi_normal(gamma_prior_mean, gamma_prior_sd);
to_vector(betaD) ~ multi_normal(betaD_prior_mean, betaD_prior_sd);
L_Omega~lkj_corr_cholesky(2);
tau~exponential(2);
to_vector(alpha)~normal(0, 1);

for (i in 1:H)
target += log_sum_exp(unalpha_Tkn[i]); // Note: update based only on last unalpha_tk
}

generated quantities{
vector[K] alpha_tk[N];
corr_matrix[nvar_ind] Omega;
matrix<lower=0, upper=1>[K, N_arms] empb_n[N];  // choice probability: pb of 1 or 0, given state, at each obs.
real log_lik[H];                    // lk based on filtered probs
matrix[K, N_arms] empbg;
vector[N_arms] W_Averageg;
vector[N_arms] ewg;
real ew1g;
  
Omega = L_Omega * L_Omega';

{ // Forward algortihm
for (n in 1:N)
alpha_tk[n] = softmax(unalpha_tk[n]);
} // Forward

for (i in 1:H)
log_lik[i]=log_sum_exp(unalpha_Tkn[i]);

{ // local section
for (n in 1:N){
  
if(T[n]==1){

ewg=rep_vector(N0, N_arms);
W_Averageg=prior;

empbg[1]=[0.333333, 0.333333, 0.333334];

for(j in 2:K)
empbg[j]=rep_row_vector(0.000001, N_arms);

empb_n[n]=empbg;

 }else{

ew1g=ewg[y[n-1]];
ewg[y[n-1]]= rho[ID[n]]*ewg[y[n-1]]+1;
W_Averageg[y[n-1]]=(phi[ID[n]]*ew1g*W_Averageg[y[n-1]]+X[n-1])/ewg[y[n-1]];

for (arm in 1:N_arms){
  //State 1 - random: keep empb[1];
    empbg[1, arm]=exp(categorical_logit_lpmf(arm|lambda_explore*W_Averageg));
    // State 2 - exploitation;
    empbg[2, arm]=exp(categorical_logit_lpmf(arm|lambda_exploit[ID[n]]*W_Averageg));
    // State 3 - inertia;
    empbg[3, arm]=(arm==y[n-1] ? 0.99995 : 0.000025);
}

empb_n[n]= empbg;
}
}
}
}
"

#* EEI/EWA full model for OOS ----
# excludes generated quantities
hmme_eei_ewa_mixed_oos = "
data {
int<lower=1> N; // Observations
int<lower=1> N_arms; // Alternatives
int<lower=1> H; // Players
int<lower=1> K; // number of hidden states
int<lower=1> D;
// vector[D] XD[N];
int<lower=1, upper=N_arms> y[N]; // Choice Indicator
int T[N]; // Rounds
int<lower=0, upper=1> lastT[N];  // vector for the time series per individual
int<lower=1> ID[N];              // vector of individual index
vector[N_arms] prior; // prior knowledge
real X[N]; // stacked observations
simplex[K] pi0;
int z[K];
real<lower=0, upper=10> N0;
int <lower=1> ndem;
matrix[H, ndem] u;
}

transformed data {
row_vector[D] zeros;
int<lower=1> nvar_ind;
int<lower=1> nvar_baseline;
int<lower=1> nvar_cov;

zeros = rep_row_vector(0, D);
nvar_ind=(K-1)*K+3;
nvar_baseline=(K-1)*K;
nvar_cov=K*(K-1)*(D-1);
}

parameters {
real lambda_explore_unt;
matrix[nvar_ind, H] alpha; // nvar*H parameter matrix
matrix[ndem, nvar_ind] gamma; // delta
cholesky_factor_corr[nvar_ind] L_Omega; // Vbeta- prior correlation
vector<lower=0>[nvar_ind] tau;
vector[nvar_cov] betaD; 
}

transformed parameters {
vector[K] unalpha_tk[N];
vector[K] unalpha_Tkn[H];
vector[N_arms] empb[K];

vector[N_arms] W_Average;
vector[N_arms] ew;
real ew1;

row_vector[D] XD;
real gl;
// vector[N_arms] r;
//vector[N_arms] Xmean;
real Xsum;
real Xmean;

matrix[K, D] beta[K, H];
vector[(K-1)] tempV;
matrix[(K-1), D] tempM;

real<lower=0, upper=1> lambda_explore;
real<lower=0, upper=1> lambda_exploit[H]; // delta
real<lower=0, upper=1> rho[H]; // delta
real<lower=0, upper=1> phi[H]; // delta

matrix[H, nvar_ind] delta;
matrix[H, nvar_ind] Vdelta_reparametrized;

Vdelta_reparametrized = (diag_pre_multiply(tau, L_Omega)*alpha)';
delta=u*gamma+Vdelta_reparametrized;

lambda_explore=inv_logit(lambda_explore_unt);

for (h in 1:H)
{
  lambda_exploit[h]=inv_logit(lambda_explore_unt+exp(delta[h,7]));
  rho[h]=inv_logit(delta[h,8]);
  phi[h]=inv_logit(delta[h,9]);
  
  for (i in 1:K)
  {
  for(l in 1:(K-1))
  {tempV[l]=delta[h,((i-1)*(K-1)+l)];}
  //matrix is filled by column;
  tempM = append_col(tempV, [betaD[(i-1)*(K-1)+1], betaD[(i-1)*(K-1)+2]]');
  beta[i, h]= append_row(tempM, zeros);
  }
}

// Transition probabilities
for (n in 1:N)
{ // Forwards algorithm log p(z_t = j | x_{1:t})
real accumulator[K];

// at T=1
if(T[n]==1){
ew=rep_vector(N0, N_arms);
W_Average=prior;
Xmean=prior[1];
Xsum=prior[1];

empb[1]=[0.333333, 0.333333, 0.333334]';
for(j in 2:K)
empb[j]=rep_vector(0.000001, N_arms);

for (j in 1:K) {
// everyone starts in state 1;
unalpha_tk[n][j] =log(pi0[j]) + log(empb[j, y[n]]);
}

gl=(X[n]>Xmean ? 0 : 1);
Xsum=Xsum+X[n];
Xmean=Xsum/(T[n]+1);

}else{

//gain/ loss: it's a raw vector;
XD=[1, gl];

ew1=ew[y[n-1]];
ew[y[n-1]]= rho[ID[n]]*ew[y[n-1]]+1;
W_Average[y[n-1]]=(phi[ID[n]]*ew1*W_Average[y[n-1]]+X[n-1])/ew[y[n-1]];

//State 1 - random: keep empb[1];
// empb[1]=log([0.333333, 0.333333, 0.333334]');
// State 2 - exploitation;
for(arm in 1:N_arms)
{empb[1, arm]=categorical_logit_lpmf(arm|lambda_explore*W_Average);
empb[2, arm]=categorical_logit_lpmf(arm|lambda_exploit[ID[n]]*W_Average);
// State 3 - inertia;
empb[3, arm]=log(arm==y[n-1] ? 0.99995 : 0.000025);}

for (j in 1:K) { // j = current (t)
for (i in 1:K) { // i = previous (t-1)
// Murphy (2012) Eq. 17.48
// belief state + transition prob + local evidence at t
accumulator[i] = unalpha_tk[n-1, i]+categorical_logit_lpmf(z[j]|to_vector(XD*beta[i,ID[n]]')) + empb[j, y[n]];
}
unalpha_tk[n, j] = log_sum_exp(accumulator);
}

gl=(X[n]>Xmean ? 0 : 1);
Xsum=Xsum+X[n];
Xmean=Xsum/(T[n]+1);

}

if(lastT[n]==1)
{unalpha_Tkn[ID[n]]=unalpha_tk[n];}
} // Forward
}

model {
lambda_explore_unt ~ normal(0,1);
to_vector(gamma) ~ normal(0, 1);
to_vector(betaD)~normal(0,1);
L_Omega~lkj_corr_cholesky(2);
tau~exponential(1);
to_vector(alpha)~normal(0, 1);

for (i in 1:H)
target += log_sum_exp(unalpha_Tkn[i]); // Note: update based only on last unalpha_tk
}

generated quantities{
vector[K] alpha_tk[N];

{ // Forward algortihm
for (n in 1:N)
alpha_tk[n] = softmax(unalpha_tk[n]);
} // Forward

}
"

#* EE/EWA model ----
hmme_ee_only_ewa_mixed="
functions {
vector normalize(vector x) {
return x / sum(x);
}
}

data {
int<lower=1> N; // Observations
int<lower=1> N_arms; // Alternatives
int<lower=1> H; // Players
int<lower=1> K; // number of hidden states
int<lower=1> D;
int<lower=1, upper=N_arms> y[N]; // Choice Indicator
int T[N]; // Rounds
int<lower=0, upper=1> lastT[N];  // vector for the time series per individual
int<lower=1> ID[N];              // vector of individual index
vector[N_arms] prior; // prior knowledge
real X[N]; // stacked observations
simplex[K] pi0;
int z[K];
real<lower=0, upper=10> N0;
int <lower=1> ndem;
matrix[H, ndem] u;
}

transformed data {
row_vector[D] zeros;
int<lower=1> nvar_ind;
int<lower=1> nvar_baseline;
int<lower=1> nvar_cov;

zeros = rep_row_vector(0, D);
nvar_ind=(K-1)*K+3;
nvar_baseline=(K-1)*K;
nvar_cov=K*(K-1)*(D-1);
}

parameters {
real lambda_explore_unt;
matrix[nvar_ind, H] alpha; // nvar*H parameter matrix
matrix[ndem, nvar_ind] gamma; // delta
cholesky_factor_corr[nvar_ind] L_Omega; // Vbeta- prior correlation
vector<lower=0>[nvar_ind] tau;
vector[nvar_cov] betaD; 
}

transformed parameters {
vector[K] unalpha_tk[N];
vector[K] unalpha_Tkn[H];
vector[N_arms] empb[K];

vector[N_arms] W_Average;
vector[N_arms] ew;
real ew1;

row_vector[D] XD;
real gl;
real Xsum;
real Xmean;

matrix[K, D] beta[K, H];
row_vector[D] tempM;

real<lower=0, upper=1> lambda_explore;
real<lower=0, upper=1> lambda_exploit[H]; // delta
real<lower=0, upper=1> rho[H]; // delta
real<lower=0, upper=1> phi[H]; // delta

matrix[H, nvar_ind] delta;
matrix[H, nvar_ind] Vdelta_reparametrized;

Vdelta_reparametrized = (diag_pre_multiply(tau, L_Omega)*alpha)';
delta=u*gamma+Vdelta_reparametrized;

lambda_explore=inv_logit(lambda_explore_unt);

for (h in 1:H)
{
  lambda_exploit[h]=inv_logit(lambda_explore_unt+exp(delta[h,3]));
  rho[h]=inv_logit(delta[h,4]);
  phi[h]=inv_logit(delta[h,5]);
  
  for (i in 1:K){
  tempM = [delta[h,i], betaD[i]];
  beta[i, h]= append_row(tempM, zeros);
  }
}

// Transition probabilities
for (n in 1:N) { // Forwards algorithm log p(z_t = j | x_{1:t})
real accumulator[K];

// at T=1
if(T[n]==1){
ew=rep_vector(N0, N_arms);
W_Average=prior;
Xmean=prior[1];
Xsum=prior[1];

empb[1]=[0.333333, 0.333333, 0.333334]';
for(j in 2:K)
empb[j]=rep_vector(0.000001, N_arms);

for (j in 1:K) {
// everyone starts in state 1;
unalpha_tk[n][j] =log(pi0[j]) + log(empb[j, y[n]]);
}

gl=(X[n]>Xmean ? 0 : 1);
Xsum=Xsum+X[n];
Xmean=Xsum/(T[n]+1);

}else{

//gain/ loss: it's a raw vector;
XD=[1, gl];

ew1=ew[y[n-1]];
ew[y[n-1]]= rho[ID[n]]*ew[y[n-1]]+1;
W_Average[y[n-1]]=(phi[ID[n]]*ew1*W_Average[y[n-1]]+X[n-1])/ew[y[n-1]];

// empb[1]=log([0.333333, 0.333333, 0.333334]');

for(arm in 1:N_arms){
//State 1 - random: keep empb[1];
empb[1, arm]=categorical_logit_lpmf(arm|lambda_explore*W_Average);
// State 2 - exploitation;
empb[2, arm]=categorical_logit_lpmf(arm|lambda_exploit[ID[n]]*W_Average);
}

for (j in 1:K) { // j = current (t)
for (i in 1:K) { // i = previous (t-1)
// Murphy (2012) Eq. 17.48
// belief state + transition prob + local evidence at t
accumulator[i] = unalpha_tk[n-1, i]+categorical_logit_lpmf(z[j]|to_vector(XD*beta[i,ID[n]]')) + empb[j, y[n]];
}
unalpha_tk[n, j] = log_sum_exp(accumulator);
}

gl=(X[n]>Xmean ? 0 : 1);
Xsum=Xsum+X[n];
Xmean=Xsum/(T[n]+1);
}

if(lastT[n]==1)
{unalpha_Tkn[ID[n]]=unalpha_tk[n];}
} // Forward
}

model {
lambda_explore_unt ~ normal(0,1);
to_vector(gamma) ~ normal(0, 1);
to_vector(betaD)~normal(0,1);
L_Omega~lkj_corr_cholesky(2);
tau~exponential(1);
to_vector(alpha)~normal(0, 1);

for (i in 1:H)
target += log_sum_exp(unalpha_Tkn[i]); // Note: update based only on last unalpha_tk
}

generated quantities{
vector[K] alpha_tk[N];
corr_matrix[nvar_ind] Omega;
matrix<lower=0, upper=1>[K, N_arms] empb_n[N];  // choice probability: pb of 1 or 0, given state, at each obs.
real log_lik[H];                    // lk based on filtered probs
matrix[K, N_arms] empbg;
vector[N_arms] W_Averageg;
vector[N_arms] ewg;
real ew1g;
  
Omega = L_Omega * L_Omega';

{ // Forward algortihm
for (n in 1:N)
alpha_tk[n] = softmax(unalpha_tk[n]);
} // Forward

for (i in 1:H)
log_lik[i]=log_sum_exp(unalpha_Tkn[i]);

{ // local section
for (n in 1:N){
  
if(T[n]==1){

ewg=rep_vector(N0, N_arms);
W_Averageg=prior;

empbg[1]=[0.333333, 0.333333, 0.333334];

for(j in 2:K)
empbg[j]=rep_row_vector(0.000001, N_arms);

empb_n[n]=empbg;

 }else{

ew1g=ewg[y[n-1]];
ewg[y[n-1]]= rho[ID[n]]*ewg[y[n-1]]+1;
W_Averageg[y[n-1]]=(phi[ID[n]]*ew1g*W_Averageg[y[n-1]]+X[n-1])/ewg[y[n-1]];

for (arm in 1:N_arms){
  //State 1 - random: keep empb[1];
    empbg[1, arm]=exp(categorical_logit_lpmf(arm|lambda_explore*W_Averageg));
    // State 2 - exploitation;
    empbg[2, arm]=exp(categorical_logit_lpmf(arm|lambda_exploit[ID[n]]*W_Averageg));
  }

empb_n[n]= empbg;
}
}
}
}
"

#* EE/EWA model for OOS ----
# excludes generated quantities
hmme_ee_only_ewa_mixed_oos = "
data {
int<lower=1> N; // Observations
int<lower=1> N_arms; // Alternatives
int<lower=1> H; // Players
int<lower=1> K; // number of hidden states
int<lower=1> D;
// vector[D] XD[N];
int<lower=1, upper=N_arms> y[N]; // Choice Indicator
int T[N]; // Rounds
int<lower=0, upper=1> lastT[N];  // vector for the time series per individual
int<lower=1> ID[N];              // vector of individual index
vector[N_arms] prior; // prior knowledge
real X[N]; // stacked observations
simplex[K] pi0;
int z[K];
real<lower=0, upper=10> N0;
int <lower=1> ndem;
matrix[H, ndem] u;
}

transformed data {
row_vector[D] zeros;
int<lower=1> nvar_ind;
int<lower=1> nvar_baseline;
int<lower=1> nvar_cov;

zeros = rep_row_vector(0, D);
nvar_ind=(K-1)*K+3;
nvar_baseline=(K-1)*K;
nvar_cov=K*(K-1)*(D-1);
}

parameters {
real lambda_explore_unt;
matrix[nvar_ind, H] alpha; // nvar*H parameter matrix
matrix[ndem, nvar_ind] gamma; // delta
cholesky_factor_corr[nvar_ind] L_Omega; // Vbeta- prior correlation
vector<lower=0>[nvar_ind] tau;
vector[nvar_cov] betaD; 
}

transformed parameters {
vector[K] unalpha_tk[N];
vector[K] unalpha_Tkn[H];
vector[N_arms] empb[K];

vector[N_arms] W_Average;
vector[N_arms] ew;
real ew1;

row_vector[D] XD;
real gl;
real Xsum;
real Xmean;

matrix[K, D] beta[K, H];
row_vector[D] tempM;

real<lower=0, upper=1> lambda_explore;
real<lower=0, upper=1> lambda_exploit[H]; // delta
real<lower=0, upper=1> rho[H]; // delta
real<lower=0, upper=1> phi[H]; // delta

matrix[H, nvar_ind] delta;
matrix[H, nvar_ind] Vdelta_reparametrized;

Vdelta_reparametrized = (diag_pre_multiply(tau, L_Omega)*alpha)';
delta=u*gamma+Vdelta_reparametrized;

lambda_explore=inv_logit(lambda_explore_unt);

for (h in 1:H)
{
  lambda_exploit[h]=inv_logit(lambda_explore_unt+exp(delta[h,3]));
  rho[h]=inv_logit(delta[h,4]);
  phi[h]=inv_logit(delta[h,5]);
  
  for (i in 1:K){
  tempM = [delta[h,i], betaD[i]];
  beta[i, h]= append_row(tempM, zeros);
  }
}
//print(beta);

// Transition probabilities
for (n in 1:N)
{ // Forwards algorithm log p(z_t = j | x_{1:t})
real accumulator[K];

// at T=1
if(T[n]==1){
ew=rep_vector(N0, N_arms);
W_Average=prior;
Xmean=prior[1];
Xsum=prior[1];

empb[1]=[0.333333, 0.333333, 0.333334]';
for(j in 2:K)
empb[j]=rep_vector(0.000001, N_arms);

for (j in 1:K) {
// everyone starts in state 1;
unalpha_tk[n][j] =log(pi0[j]) + log(empb[j, y[n]]);
}

gl=(X[n]>Xmean ? 0 : 1);
Xsum=Xsum+X[n];
Xmean=Xsum/(T[n]+1);

}else{

//gain/ loss: it's a raw vector;
XD=[1, gl];

ew1=ew[y[n-1]];
ew[y[n-1]]= rho[ID[n]]*ew[y[n-1]]+1;
W_Average[y[n-1]]=(phi[ID[n]]*ew1*W_Average[y[n-1]]+X[n-1])/ew[y[n-1]];

// empb[1]=log([0.333333, 0.333333, 0.333334]');

for(arm in 1:N_arms)
{//State 1 - random: keep empb[1];
empb[1, arm]=categorical_logit_lpmf(arm|lambda_explore*W_Average);
// State 2 - exploitation;
empb[2, arm]=categorical_logit_lpmf(arm|lambda_exploit[ID[n]]*W_Average);
}

for (j in 1:K) { // j = current (t)
for (i in 1:K) { // i = previous (t-1)
// Murphy (2012) Eq. 17.48
// belief state + transition prob + local evidence at t
accumulator[i] = unalpha_tk[n-1, i]+categorical_logit_lpmf(z[j]|to_vector(XD*beta[i,ID[n]]')) + empb[j, y[n]];
}
unalpha_tk[n, j] = log_sum_exp(accumulator);
}

gl=(X[n]>Xmean ? 0 : 1);
Xsum=Xsum+X[n];
Xmean=Xsum/(T[n]+1);
}

if(lastT[n]==1)
{unalpha_Tkn[ID[n]]=unalpha_tk[n];}

} // Forward
}

model {
lambda_explore_unt ~ normal(0,1);
to_vector(gamma) ~ normal(0, 1);
to_vector(betaD)~normal(0,1);
L_Omega~lkj_corr_cholesky(2);
tau~exponential(1);
to_vector(alpha)~normal(0, 1);

for (i in 1:H)
target += log_sum_exp(unalpha_Tkn[i]); // Note: update based only on last unalpha_tk
}

generated quantities{
vector[K] alpha_tk[N];

{ // Forward algortihm
for (n in 1:N)
alpha_tk[n] = softmax(unalpha_tk[n]);
} // Forward

}
"

#* EEI/EWA with discounted EV ----
hmme_eei_ewa_mixed_discountEV="
functions {
vector normalize(vector x) {
return x / sum(x);
}
}

data {
int<lower=1> N; // Observations
int<lower=1> N_arms; // Alternatives
int<lower=1> H; // Players
int<lower=1> K; // number of hidden states
int<lower=1> D;
// vector[D] XD[N];
int<lower=1, upper=N_arms> y[N]; // Choice Indicator
int T[N]; // Rounds
int<lower=0, upper=1> lastT[N];  // vector for the time series per individual
int<lower=1> ID[N];              // vector of individual index
vector[N_arms] prior; // prior knowledge
real X[N]; // stacked observations
simplex[K] pi0;
int z[K];
real<lower=0, upper=10> N0;
int <lower=1> ndem;
matrix[H, ndem] u;
real<lower=0, upper=1> r;
}

transformed data {
row_vector[D] zeros;
int<lower=1> nvar_ind;
int<lower=1> nvar_baseline;
int<lower=1> nvar_cov;

zeros = rep_row_vector(0, D);
nvar_ind=(K-1)*K+3;
nvar_baseline=(K-1)*K;
nvar_cov=K*(K-1)*(D-1);
}

parameters {
real lambda_explore_unt;
matrix[nvar_ind, H] alpha; // nvar*H parameter matrix
matrix[ndem, nvar_ind] gamma; // delta
cholesky_factor_corr[nvar_ind] L_Omega; // Vbeta- prior correlation
vector<lower=0>[nvar_ind] tau;
vector[nvar_cov] betaD; 
}

transformed parameters {
vector[K] unalpha_tk[N];
vector[K] unalpha_Tkn[H];
vector[N_arms] empb[K];

vector[N_arms] W_Average;
vector[N_arms] ew;
real ew1;

row_vector[D] XD;
real gl;
real Nr;
real Xmean;

matrix[K, D] beta[K, H];
vector[(K-1)] tempV;
matrix[(K-1), D] tempM;

real<lower=0, upper=1> lambda_explore;
real<lower=0, upper=1> lambda_exploit[H]; // delta
real<lower=0, upper=1> rho[H]; // delta
real<lower=0, upper=1> phi[H]; // delta

matrix[H, nvar_ind] delta;
matrix[H, nvar_ind] Vdelta_reparametrized;

Vdelta_reparametrized = (diag_pre_multiply(tau, L_Omega)*alpha)';
delta=u*gamma+Vdelta_reparametrized;

lambda_explore=inv_logit(lambda_explore_unt);

for (h in 1:H)
{
  lambda_exploit[h]=inv_logit(lambda_explore_unt+exp(delta[h,7]));
  rho[h]=inv_logit(delta[h,8]);
  phi[h]=inv_logit(delta[h,9]);
  // r[h]=inv_logit(delta[h,10]);
  
  for (i in 1:K)
  {
  for(l in 1:(K-1))
  {tempV[l]=delta[h,((i-1)*(K-1)+l)];}
  //matrix is filled by column;
  tempM = append_col(tempV, [betaD[(i-1)*(K-1)+1], betaD[(i-1)*(K-1)+2]]');
  beta[i, h] = append_row(tempM, zeros);
  }
}
//print(beta);

// Transition probabilities
for (n in 1:N)
{ // Forwards algorithm log p(z_t = j | x_{1:t})
real accumulator[K];

// at T=1
if(T[n]==1){
ew=rep_vector(N0, N_arms);
W_Average=prior;

empb[1]=[0.333333, 0.333333, 0.333334]';
for(j in 2:K)
empb[j]=rep_vector(0.000001, N_arms);

for (j in 1:K) {
// everyone starts in state 1;
unalpha_tk[n][j] =log(pi0[j]) + log(empb[j, y[n]]);
}


Xmean=prior[1];
Nr=1; //prior weight on expected value, set at 1.
gl=(X[n]>Xmean ? 0 : 1);

Xmean=(r*Nr*Xmean+X[n])/(r*Nr+1);
Nr=r*Nr+1;

}else{
// for (t in 2:T) {;

//gain/ loss: it's a raw vector;
XD=[1, gl];

ew1=ew[y[n-1]];
ew[y[n-1]]= rho[ID[n]]*ew[y[n-1]]+1;
W_Average[y[n-1]]=(phi[ID[n]]*ew1*W_Average[y[n-1]]+X[n-1])/ew[y[n-1]];

//State 1 - random: keep empb[1];
// empb[1]=log([0.333333, 0.333333, 0.333334]');
// State 2 - exploitation;
for(arm in 1:N_arms)
{empb[1, arm]=categorical_logit_lpmf(arm|lambda_explore*W_Average);
empb[2, arm]=categorical_logit_lpmf(arm|lambda_exploit[ID[n]]*W_Average);
// State 3 - inertia;
empb[3, arm]=log(arm==y[n-1] ? 0.99995 : 0.000025);}

for (j in 1:K) { // j = current (t)
for (i in 1:K) { // i = previous (t-1)
// Murphy (2012) Eq. 17.48
// belief state + transition prob + local evidence at t
accumulator[i] = unalpha_tk[n-1, i]+categorical_logit_lpmf(z[j]|to_vector(XD*beta[i,ID[n]]')) + empb[j, y[n]];
}
unalpha_tk[n, j] = log_sum_exp(accumulator);
}


gl=(X[n]>Xmean ? 0 : 1);

Xmean=(r*Nr*Xmean+X[n])/(r*Nr+1);
Nr=r*Nr+1;

//}
}

if(lastT[n]==1)
{unalpha_Tkn[ID[n]]=unalpha_tk[n];}
} // Forward
}

model {
lambda_explore_unt ~ normal(0,1);
to_vector(gamma) ~ normal(0, 1);
to_vector(betaD)~normal(0,1);
L_Omega~lkj_corr_cholesky(2);
tau~exponential(1);
to_vector(alpha)~normal(0, 1);

for (i in 1:H)
target += log_sum_exp(unalpha_Tkn[i]); // Note: update based only on last unalpha_tk
}

generated quantities{
vector[K] alpha_tk[N];
corr_matrix[nvar_ind] Omega;
matrix<lower=0, upper=1>[K, N_arms] empb_n[N];  // choice probability: pb of 1 or 0, given state, at each obs.
real log_lik[H];                    // lk based on filtered probs
matrix[K,N_arms] empbg;
vector[N_arms] W_Averageg;
vector[N_arms] ewg;
real ew1g;
 
Omega = L_Omega * L_Omega';

{ // Forward algortihm
for (n in 1:N)
alpha_tk[n] = softmax(unalpha_tk[n]);
} // Forward

for (i in 1:H)
log_lik[i]=log_sum_exp(unalpha_Tkn[i]);

{// local section; 
for (n in 1:N){
  if(T[n]==1){
    ewg=rep_vector(N0, N_arms);
    W_Averageg=prior;

empbg[1]=[0.333333, 0.333333, 0.333334];
for(j in 2:K)
empbg[j]=rep_row_vector(0.000001, N_arms);

empb_n[n]=empbg;

}else{

ew1g=ewg[y[n-1]];
ewg[y[n-1]]= rho[ID[n]]*ewg[y[n-1]]+1;
W_Averageg[y[n-1]]=(phi[ID[n]]*ew1g*W_Averageg[y[n-1]]+X[n-1])/ewg[y[n-1]];



for(arm in 1:N_arms)
{//State 1 - exploration;
empbg[1, arm]=exp(categorical_logit_lpmf(arm|lambda_explore*W_Averageg));
// State 2 - exploitation;
empbg[2, arm]=exp(categorical_logit_lpmf(arm|lambda_exploit[ID[n]]*W_Averageg));
// State 3 - inertia;
empbg[3, arm]=(arm==y[n-1] ? 0.99995 : 0.000025);
  }
empb_n[n]= empbg;

}
}
}
}
"

#* EEI/EWA models with discounted EV for OOS ----
# excludes generated quantities
hmme_eei_ewa_mixed_discountEV_oos="
functions {
vector normalize(vector x) {
return x / sum(x);
}
}

data {
int<lower=1> N; // Observations
int<lower=1> N_arms; // Alternatives
int<lower=1> H; // Players
int<lower=1> K; // number of hidden states
int<lower=1> D;
// vector[D] XD[N];
int<lower=1, upper=N_arms> y[N]; // Choice Indicator
int T[N]; // Rounds
int<lower=0, upper=1> lastT[N];  // vector for the time series per individual
int<lower=1> ID[N];              // vector of individual index
vector[N_arms] prior; // prior knowledge
real X[N]; // stacked observations
simplex[K] pi0;
int z[K];
real<lower=0, upper=10> N0;
int <lower=1> ndem;
matrix[H, ndem] u;
real<lower=0, upper=1> r;
}

transformed data {
row_vector[D] zeros;
int<lower=1> nvar_ind;
int<lower=1> nvar_baseline;
int<lower=1> nvar_cov;

zeros = rep_row_vector(0, D);
nvar_ind=(K-1)*K+3;
nvar_baseline=(K-1)*K;
nvar_cov=K*(K-1)*(D-1);
}

parameters {
real lambda_explore_unt;
matrix[nvar_ind, H] alpha; // nvar*H parameter matrix
matrix[ndem, nvar_ind] gamma; // delta
cholesky_factor_corr[nvar_ind] L_Omega; // Vbeta- prior correlation
vector<lower=0>[nvar_ind] tau;
vector[nvar_cov] betaD; 
}

transformed parameters {
vector[K] unalpha_tk[N];
vector[K] unalpha_Tkn[H];
vector[N_arms] empb[K];

vector[N_arms] W_Average;
vector[N_arms] ew;
real ew1;

row_vector[D] XD;
real gl;
real Nr;
real Xmean;

matrix[K, D] beta[K, H];
vector[(K-1)] tempV;
matrix[(K-1), D] tempM;

real<lower=0, upper=1> lambda_explore;
real<lower=0, upper=1> lambda_exploit[H]; // delta
real<lower=0, upper=1> rho[H]; // delta
real<lower=0, upper=1> phi[H]; // delta

matrix[H, nvar_ind] delta;
matrix[H, nvar_ind] Vdelta_reparametrized;

Vdelta_reparametrized = (diag_pre_multiply(tau, L_Omega)*alpha)';
delta=u*gamma+Vdelta_reparametrized;

lambda_explore=inv_logit(lambda_explore_unt);

for (h in 1:H)
{
  lambda_exploit[h]=inv_logit(lambda_explore_unt+exp(delta[h,7]));
  rho[h]=inv_logit(delta[h,8]);
  phi[h]=inv_logit(delta[h,9]);
  // r[h]=inv_logit(delta[h,10]);
  
  for (i in 1:K)
  {
  for(l in 1:(K-1))
  {tempV[l]=delta[h,((i-1)*(K-1)+l)];}
  //matrix is filled by column;
  tempM = append_col(tempV, [betaD[(i-1)*(K-1)+1], betaD[(i-1)*(K-1)+2]]');
  beta[i, h] = append_row(tempM, zeros);
  }
}
//print(beta);

// Transition probabilities
for (n in 1:N)
{ // Forwards algorithm log p(z_t = j | x_{1:t})
real accumulator[K];

// at T=1
if(T[n]==1){
ew=rep_vector(N0, N_arms);
W_Average=prior;

empb[1]=[0.333333, 0.333333, 0.333334]';
for(j in 2:K)
empb[j]=rep_vector(0.000001, N_arms);

for (j in 1:K) {
// everyone starts in state 1;
unalpha_tk[n][j] =log(pi0[j]) + log(empb[j, y[n]]);
}


Xmean=prior[1];
Nr=1; //prior weight on expected value, set at 1.
gl=(X[n]>Xmean ? 0 : 1);

Xmean=(r*Nr*Xmean+X[n])/(r*Nr+1);
Nr=r*Nr+1;

}else{
// for (t in 2:T) {;

//gain/ loss: it's a raw vector;
XD=[1, gl];

ew1=ew[y[n-1]];
ew[y[n-1]]= rho[ID[n]]*ew[y[n-1]]+1;
W_Average[y[n-1]]=(phi[ID[n]]*ew1*W_Average[y[n-1]]+X[n-1])/ew[y[n-1]];

//State 1 - random: keep empb[1];
// empb[1]=log([0.333333, 0.333333, 0.333334]');
// State 2 - exploitation;
for(arm in 1:N_arms)
{empb[1, arm]=categorical_logit_lpmf(arm|lambda_explore*W_Average);
empb[2, arm]=categorical_logit_lpmf(arm|lambda_exploit[ID[n]]*W_Average);
// State 3 - inertia;
empb[3, arm]=log(arm==y[n-1] ? 0.99995 : 0.000025);}

for (j in 1:K) { // j = current (t)
for (i in 1:K) { // i = previous (t-1)
// Murphy (2012) Eq. 17.48
// belief state + transition prob + local evidence at t
accumulator[i] = unalpha_tk[n-1, i]+categorical_logit_lpmf(z[j]|to_vector(XD*beta[i,ID[n]]')) + empb[j, y[n]];
}
unalpha_tk[n, j] = log_sum_exp(accumulator);
}


gl=(X[n]>Xmean ? 0 : 1);

Xmean=(r*Nr*Xmean+X[n])/(r*Nr+1);
Nr=r*Nr+1;

//}
}

if(lastT[n]==1)
{unalpha_Tkn[ID[n]]=unalpha_tk[n];}
} // Forward
}

model {
lambda_explore_unt ~ normal(0,1);
to_vector(gamma) ~ normal(0, 1);
to_vector(betaD)~normal(0,1);
L_Omega~lkj_corr_cholesky(2);
tau~exponential(1);
to_vector(alpha)~normal(0, 1);

for (i in 1:H)
target += log_sum_exp(unalpha_Tkn[i]); // Note: update based only on last unalpha_tk
}

generated quantities{
vector[K] alpha_tk[N];

{ // Forward algortihm
for (n in 1:N)
alpha_tk[n] = softmax(unalpha_tk[n]);
} // Forward

}
"

#* statEEI/EWA ----
hmme_eei_stationary_ewa="
functions {
vector normalize(vector x) {
return x / sum(x);
}
}

data {
int<lower=1> N; // Observations
int<lower=1> N_arms; // Alternatives
int<lower=1> H; // Players
int<lower=1> K; // number of hidden states
// vector[D] XD[N];
int<lower=1, upper=N_arms> y[N]; // Choice Indicator
int T[N]; // Rounds
int<lower=0, upper=1> lastT[N];  // vector for the time series per individual
int<lower=1> ID[N];              // vector of individual index
vector[N_arms] prior; // prior knowledge =50
real X[N]; // stacked observations
simplex[K] pi0;
int z[K];
real<lower=0, upper=10> N0;
int <lower=1> ndem;
matrix[H, ndem] u;
}

transformed data {
int<lower=1> nvar_ind;
int<lower=1> nvar_baseline;

nvar_ind=(K-1)*K+3;
nvar_baseline=(K-1)*K;
}

parameters {
real lambda_explore_unt;
matrix[nvar_ind, H] alpha; // nvar*H parameter matrix
matrix[ndem, nvar_ind] gamma; // delta
cholesky_factor_corr[nvar_ind] L_Omega; // Vbeta- prior correlation
vector<lower=0>[nvar_ind] tau;
}

transformed parameters {
vector[K] unalpha_tk[N];
vector[K] unalpha_Tkn[H];
vector[N_arms] empb[K];

vector[N_arms] W_Average;
vector[N_arms] ew;
real ew1;

vector[K] beta[K, H];
vector[(K-1)] tempV;

real<lower=0, upper=1> lambda_explore;
real<lower=0, upper=1> lambda_exploit[H]; // delta
real<lower=0, upper=1> rho[H]; // delta
real<lower=0, upper=1> phi[H]; // delta

matrix[H, nvar_ind] delta;
matrix[H, nvar_ind] Vdelta_reparametrized;

Vdelta_reparametrized = (diag_pre_multiply(tau, L_Omega)*alpha)';
delta=u*gamma+Vdelta_reparametrized;

lambda_explore=inv_logit(lambda_explore_unt);

for (h in 1:H)
{
  lambda_exploit[h]=inv_logit(lambda_explore_unt+exp(delta[h,7]));
  rho[h]=inv_logit(delta[h,8]);
  phi[h]=inv_logit(delta[h,9]);
  
  for (i in 1:K)
  {
  for(l in 1:(K-1))
  {tempV[l]=delta[h,((i-1)*(K-1)+l)];}
  //matrix is filled by column;
  beta[i, h]= append_row(tempV, 0);
  }
}
//print(beta);

// Transition probabilities
for (n in 1:N)
{ // Forwards algorithm log p(z_t = j | x_{1:t})
real accumulator[K];

// at T=1
if(T[n]==1){
ew=rep_vector(N0, N_arms);
W_Average=prior;

empb[1]=[0.333333, 0.333333, 0.333334]';
for(j in 2:K)
empb[j]=rep_vector(0.000001, N_arms);

for (j in 1:K) {
// everyone starts in state 1;
unalpha_tk[n][j] =log(pi0[j]) + log(empb[j, y[n]]);
}

}else{
// for (t in 2:T) {;

ew1=ew[y[n-1]];
ew[y[n-1]]= rho[ID[n]]*ew[y[n-1]]+1;
W_Average[y[n-1]]=(phi[ID[n]]*ew1*W_Average[y[n-1]]+X[n-1])/ew[y[n-1]];

//State 1 - random: keep empb[1];
// empb[1]=log([0.333333, 0.333333, 0.333334]');
// State 2 - exploitation;
for(arm in 1:N_arms)
{empb[1, arm]=categorical_logit_lpmf(arm|lambda_explore*W_Average);
empb[2, arm]=categorical_logit_lpmf(arm|lambda_exploit[ID[n]]*W_Average);
// State 3 - inertia;
empb[3, arm]=log(arm==y[n-1] ? 0.99995 : 0.000025);}

for (j in 1:K) { // j = current (t)
for (i in 1:K) { // i = previous (t-1)
// Murphy (2012) Eq. 17.48
// belief state + transition prob + local evidence at t
accumulator[i] = unalpha_tk[n-1, i]+categorical_logit_lpmf(z[j]|beta[i,ID[n]]) + empb[j, y[n]];
}
unalpha_tk[n, j] = log_sum_exp(accumulator);
}

//}
}

if(lastT[n]==1)
{unalpha_Tkn[ID[n]]=unalpha_tk[n];}
} // Forward
}

model {
lambda_explore_unt ~ normal(0,1);
to_vector(gamma) ~ normal(0, 1);
L_Omega~lkj_corr_cholesky(2);
tau~exponential(1);
to_vector(alpha)~normal(0, 1);

for (i in 1:H)
target += log_sum_exp(unalpha_Tkn[i]); // Note: update based only on last unalpha_tk
}

generated quantities{
vector[K] alpha_tk[N];
corr_matrix[nvar_ind] Omega;
matrix<lower=0, upper=1>[K, N_arms] empb_n[N];  // choice probability: pb of 1 or 0, given state, at each obs.
real log_lik[H];                    // lk based on filtered probs
matrix[K,N_arms] empbg;
vector[N_arms] W_Averageg;
vector[N_arms] ewg;
real ew1g;

Omega = L_Omega * L_Omega';

{ // Forward algortihm
for (n in 1:N)
alpha_tk[n] = softmax(unalpha_tk[n]);
} // Forward

for (i in 1:H)
log_lik[i]=log_sum_exp(unalpha_Tkn[i]);

{ //local section
for (n in 1:N){

if(T[n]==1){
ewg=rep_vector(N0, N_arms);
W_Averageg=prior;

empbg[1]=[0.333333, 0.333333, 0.333334];
for(j in 2:K)
empbg[j]=rep_row_vector(0.000001, N_arms);

empb_n[n]=empbg;

}else{
ew1g=ewg[y[n-1]];
ewg[y[n-1]]= rho[ID[n]]*ewg[y[n-1]]+1;
W_Averageg[y[n-1]]=(phi[ID[n]]*ew1g*W_Averageg[y[n-1]]+X[n-1])/ewg[y[n-1]];

//State 1 - random: keep empb[1];
// empb[1]=log([0.333333, 0.333333, 0.333334]');
// State 2 - exploitation;
for(arm in 1:N_arms)
{empbg[1, arm]=exp(categorical_logit_lpmf(arm|lambda_explore*W_Averageg));
empbg[2, arm]=exp(categorical_logit_lpmf(arm|lambda_exploit[ID[n]]*W_Averageg));
// State 3 - inertia;
empbg[3, arm]=(arm==y[n-1] ? 0.99995 : 0.000025);}

empb_n[n]= empbg;
}
}
}
}
"
#* statEEI/EWA for OOS ----
# excludes generated quantities
hmme_eei_stationary_ewa_oos="
functions {
vector normalize(vector x) {
return x / sum(x);
}
}

data {
int<lower=1> N; // Observations
int<lower=1> N_arms; // Alternatives
int<lower=1> H; // Players
int<lower=1> K; // number of hidden states
// vector[D] XD[N];
int<lower=1, upper=N_arms> y[N]; // Choice Indicator
int T[N]; // Rounds
int<lower=0, upper=1> lastT[N];  // vector for the time series per individual
int<lower=1> ID[N];              // vector of individual index
vector[N_arms] prior; // prior knowledge =50
real X[N]; // stacked observations
simplex[K] pi0;
int z[K];
real<lower=0, upper=10> N0;
int <lower=1> ndem;
matrix[H, ndem] u;
}

transformed data {
int<lower=1> nvar_ind;
int<lower=1> nvar_baseline;

nvar_ind=(K-1)*K+3;
nvar_baseline=(K-1)*K;
}

parameters {
real lambda_explore_unt;
matrix[nvar_ind, H] alpha; // nvar*H parameter matrix
matrix[ndem, nvar_ind] gamma; // delta
cholesky_factor_corr[nvar_ind] L_Omega; // Vbeta- prior correlation
vector<lower=0>[nvar_ind] tau;
}

transformed parameters {
vector[K] unalpha_tk[N];
vector[K] unalpha_Tkn[H];
vector[N_arms] empb[K];

vector[N_arms] W_Average;
vector[N_arms] ew;
real ew1;

vector[K] beta[K, H];
vector[(K-1)] tempV;

real<lower=0, upper=1> lambda_explore;
real<lower=0, upper=1> lambda_exploit[H]; // delta
real<lower=0, upper=1> rho[H]; // delta
real<lower=0, upper=1> phi[H]; // delta

matrix[H, nvar_ind] delta;
matrix[H, nvar_ind] Vdelta_reparametrized;

Vdelta_reparametrized = (diag_pre_multiply(tau, L_Omega)*alpha)';
delta=u*gamma+Vdelta_reparametrized;

lambda_explore=inv_logit(lambda_explore_unt);

for (h in 1:H)
{
  lambda_exploit[h]=inv_logit(lambda_explore_unt+exp(delta[h,7]));
  rho[h]=inv_logit(delta[h,8]);
  phi[h]=inv_logit(delta[h,9]);
  
  for (i in 1:K)
  {
  for(l in 1:(K-1))
  {tempV[l]=delta[h,((i-1)*(K-1)+l)];}
  //matrix is filled by column;
  beta[i, h]= append_row(tempV, 0);
  }
}

// Transition probabilities
for (n in 1:N)
{ // Forwards algorithm log p(z_t = j | x_{1:t})
real accumulator[K];

// at T=1
if(T[n]==1){
ew=rep_vector(N0, N_arms);
W_Average=prior;

empb[1]=[0.333333, 0.333333, 0.333334]';
for(j in 2:K)
empb[j]=rep_vector(0.000001, N_arms);

for (j in 1:K) {
// everyone starts in state 1;
unalpha_tk[n][j] =log(pi0[j]) + log(empb[j, y[n]]);
}

}else{
// for (t in 2:T) {;

ew1=ew[y[n-1]];
ew[y[n-1]]= rho[ID[n]]*ew[y[n-1]]+1;
W_Average[y[n-1]]=(phi[ID[n]]*ew1*W_Average[y[n-1]]+X[n-1])/ew[y[n-1]];

//State 1 - random: keep empb[1];
// empb[1]=log([0.333333, 0.333333, 0.333334]');
// State 2 - exploitation;
for(arm in 1:N_arms)
{empb[1, arm]=categorical_logit_lpmf(arm|lambda_explore*W_Average);
empb[2, arm]=categorical_logit_lpmf(arm|lambda_exploit[ID[n]]*W_Average);
// State 3 - inertia;
empb[3, arm]=log(arm==y[n-1] ? 0.99995 : 0.000025);}

for (j in 1:K) { // j = current (t)
for (i in 1:K) { // i = previous (t-1)
// Murphy (2012) Eq. 17.48
// belief state + transition prob + local evidence at t
accumulator[i] = unalpha_tk[n-1, i]+categorical_logit_lpmf(z[j]|beta[i,ID[n]]) + empb[j, y[n]];
}
unalpha_tk[n, j] = log_sum_exp(accumulator);
}

//}
}

if(lastT[n]==1)
{unalpha_Tkn[ID[n]]=unalpha_tk[n];}
} // Forward
}

model {
lambda_explore_unt ~ normal(0,1);
to_vector(gamma) ~ normal(0, 1);
L_Omega~lkj_corr_cholesky(2);
tau~exponential(1);
to_vector(alpha)~normal(0, 1);

for (i in 1:H)
target += log_sum_exp(unalpha_Tkn[i]); // Note: update based only on last unalpha_tk
}

generated quantities{
vector[K] alpha_tk[N];

{ // Forward algortihm
for (n in 1:N)
alpha_tk[n] = softmax(unalpha_tk[n]);
} // Forward
}

"
#* EEI model (no belief updating) ----
hmme_eei_mixed_noEWA="
functions {
vector normalize(vector x) {
return x / sum(x);
}
}

data {
int<lower=1> N; // Observations
int<lower=1> N_arms; // Alternatives
int<lower=1> H; // Players
int<lower=1> K; // number of hidden states
int<lower=1> D;
// vector[D] XD[N];
int<lower=1, upper=N_arms> y[N]; // Choice Indicator
int T[N]; // Rounds
int<lower=0, upper=1> lastT[N];  // vector for the time series per individual
int<lower=1> ID[N];              // vector of individual index
vector[N_arms] prior; // prior knowledge =50
real X[N]; // stacked observations
simplex[K] pi0;
int z[K];
real<lower=0, upper=10> N0;
int <lower=1> ndem;
matrix[H, ndem] u;
}

transformed data {
row_vector[D] zeros;
int<lower=1> nvar_ind;
int<lower=1> nvar_baseline;
int<lower=1> nvar_cov;

zeros = rep_row_vector(0, D);
nvar_ind=(K-1)*K;
nvar_baseline=(K-1)*K;
nvar_cov=K*(K-1)*(D-1);
}

parameters {
matrix[nvar_ind, H] alpha; // nvar*H parameter matrix
matrix[ndem, nvar_ind] gamma; // delta
cholesky_factor_corr[nvar_ind] L_Omega; // Vbeta- prior correlation
vector<lower=0>[nvar_ind] tau;
vector[nvar_cov] betaD; 
}

transformed parameters {
vector[K] unalpha_tk[N];
vector[K] unalpha_Tkn[H];
vector[N_arms] empb[K];
// computes running averages per arm;
vector[N_arms] W_Average;
vector[N_arms] ew;
real ew1;

row_vector[D] XD;
real gl;
real Xsum;
real Xmean;

matrix[K, D] beta[K, H];
vector[(K-1)] tempV;
matrix[(K-1), D] tempM;

matrix[H, nvar_ind] delta;
matrix[H, nvar_ind] Vdelta_reparametrized;

Vdelta_reparametrized = (diag_pre_multiply(tau, L_Omega)*alpha)';
delta=u*gamma+Vdelta_reparametrized;

for (h in 1:H)
{
  for (i in 1:K)
  {
  for(l in 1:(K-1))
  {tempV[l]=delta[h,((i-1)*(K-1)+l)];}
  //matrix is filled by column;
  tempM = append_col(tempV, [betaD[(i-1)*(K-1)+1], betaD[(i-1)*(K-1)+2]]');
  beta[i, h]= append_row(tempM, zeros);
  }
}
//print(beta);

// Transition probabilities
for (n in 1:N)
{ // Forwards algorithm log p(z_t = j | x_{1:t})
real accumulator[K];

// at T=1
if(T[n]==1){
ew=rep_vector(N0, N_arms);
W_Average=prior;
Xmean=prior[1];
Xsum=prior[1];

empb[1]=[0.333333, 0.333333, 0.333334]';
for(j in 2:K)
empb[j]=rep_vector(0.000001, N_arms);

for (j in 1:K) {
// everyone starts in state 1;
unalpha_tk[n][j] =log(pi0[j]) + log(empb[j, y[n]]);
}

gl=(X[n]>Xmean ? 0 : 1);
Xsum=Xsum+X[n];
Xmean=Xsum/(T[n]+1);


}else{
// for (t in 2:T) {;

//gain/ loss: it's a raw vector;
XD=[1, gl];
// computes running average;
ew1=ew[y[n-1]];
ew[y[n-1]]= ew[y[n-1]]+1;
W_Average[y[n-1]]=(ew1*W_Average[y[n-1]]+X[n-1])/ew[y[n-1]];

for(arm in 1:N_arms)
{//State 1 - random: keep empb[1];
empb[1, arm]=log(0.333333333333333333333333333);
// State 2 - exploitation;
empb[2, arm]=categorical_logit_lpmf(arm|W_Average);
// State 3 - inertia;
empb[3, arm]=log(arm==y[n-1] ? 0.99995 : 0.000025);}

for (j in 1:K) { // j = current (t)
for (i in 1:K) { // i = previous (t-1)
// Murphy (2012) Eq. 17.48
// belief state + transition prob + local evidence at t
accumulator[i] = unalpha_tk[n-1, i]+categorical_logit_lpmf(z[j]|to_vector(XD*beta[i,ID[n]]')) + empb[j, y[n]];
}
unalpha_tk[n, j] = log_sum_exp(accumulator);
}

gl=(X[n]>Xmean ? 0 : 1);
Xsum=Xsum+X[n];
Xmean=Xsum/(T[n]+1);

//}
}

if(lastT[n]==1)
{unalpha_Tkn[ID[n]]=unalpha_tk[n];}
} // Forward
}

model {
to_vector(gamma) ~ normal(0, 1);
to_vector(betaD)~normal(0,1);
L_Omega~lkj_corr_cholesky(2);
tau~exponential(1);
to_vector(alpha)~normal(0, 1);

for (i in 1:H)
target += log_sum_exp(unalpha_Tkn[i]); // Note: update based only on last unalpha_tk
}

generated quantities{
vector[K] alpha_tk[N];
corr_matrix[nvar_ind] Omega;
matrix<lower=0, upper=1>[K, N_arms] empb_n[N];  // choice probability: pb of 1 or 0, given state, at each obs.
real log_lik[H];                    // lk based on filtered probs

matrix[K,N_arms] empbg;
vector[N_arms] W_Averageg;
vector[N_arms] ewg;
real ew1g;

Omega = L_Omega * L_Omega';

{ // Forward algortihm
for (n in 1:N)
alpha_tk[n] = softmax(unalpha_tk[n]);
} // Forward

for (i in 1:H)
log_lik[i]=log_sum_exp(unalpha_Tkn[i]);

{ // local section
for (n in 1:N){

if(T[n]==1){
ewg=rep_vector(N0, N_arms);
W_Averageg=prior;

empbg[1]=[0.333333, 0.333333, 0.333334];
for(j in 2:K)
empbg[j]=rep_row_vector(0.000001, N_arms);

empb_n[n]=empbg;

}else{

ew1g=ewg[y[n-1]];
ewg[y[n-1]]= ewg[y[n-1]]+1;
W_Averageg[y[n-1]]=(ew1g*W_Averageg[y[n-1]]+X[n-1])/ewg[y[n-1]];

for(arm in 1:N_arms){
//State 1 - random: keep empb[1];
empbg[1, arm]=0.3333333333333;
// State 2 - exploitation;
empbg[2, arm]=exp(categorical_logit_lpmf(arm|W_Averageg));
// State 3 - inertia;
empbg[3, arm]=(arm==y[n-1] ? 0.99995 : 0.000025);
}

empb_n[n]= empbg;
}
}
}
}
"
#* EEI model (no belief updating) for OOS ----
# excludes generated quantities

hmme_eei_mixed_noEWA_oos="
functions {
vector normalize(vector x) {
return x / sum(x);
}
}

data {
int<lower=1> N; // Observations
int<lower=1> N_arms; // Alternatives
int<lower=1> H; // Players
int<lower=1> K; // number of hidden states
int<lower=1> D;
// vector[D] XD[N];
int<lower=1, upper=N_arms> y[N]; // Choice Indicator
int T[N]; // Rounds
int<lower=0, upper=1> lastT[N];  // vector for the time series per individual
int<lower=1> ID[N];              // vector of individual index
vector[N_arms] prior; // prior knowledge =50
real X[N]; // stacked observations
simplex[K] pi0;
int z[K];
real<lower=0, upper=10> N0;
int <lower=1> ndem;
matrix[H, ndem] u;
}

transformed data {
row_vector[D] zeros;
int<lower=1> nvar_ind;
int<lower=1> nvar_baseline;
int<lower=1> nvar_cov;

zeros = rep_row_vector(0, D);
nvar_ind=(K-1)*K;
nvar_baseline=(K-1)*K;
nvar_cov=K*(K-1)*(D-1);
}

parameters {
matrix[nvar_ind, H] alpha; // nvar*H parameter matrix
matrix[ndem, nvar_ind] gamma; // delta
cholesky_factor_corr[nvar_ind] L_Omega; // Vbeta- prior correlation
vector<lower=0>[nvar_ind] tau;
vector[nvar_cov] betaD; 
}

transformed parameters {
vector[K] unalpha_tk[N];
vector[K] unalpha_Tkn[H];
vector[N_arms] empb[K];
// computes running averages per arm;
vector[N_arms] W_Average;
vector[N_arms] ew;
real ew1;

row_vector[D] XD;
real gl;
real Xsum;
real Xmean;

matrix[K, D] beta[K, H];
vector[(K-1)] tempV;
matrix[(K-1), D] tempM;

matrix[H, nvar_ind] delta;
matrix[H, nvar_ind] Vdelta_reparametrized;

Vdelta_reparametrized = (diag_pre_multiply(tau, L_Omega)*alpha)';
delta=u*gamma+Vdelta_reparametrized;

for (h in 1:H)
{
  for (i in 1:K)
  {
  for(l in 1:(K-1))
  {tempV[l]=delta[h,((i-1)*(K-1)+l)];}
  //matrix is filled by column;
  tempM = append_col(tempV, [betaD[(i-1)*(K-1)+1], betaD[(i-1)*(K-1)+2]]');
  beta[i, h]= append_row(tempM, zeros);
  }
}
//print(beta);

// Transition probabilities
for (n in 1:N)
{ // Forwards algorithm log p(z_t = j | x_{1:t})
real accumulator[K];

// at T=1
if(T[n]==1){
ew=rep_vector(N0, N_arms);
W_Average=prior;
Xmean=prior[1];
Xsum=prior[1];

empb[1]=[0.333333, 0.333333, 0.333334]';
for(j in 2:K)
empb[j]=rep_vector(0.000001, N_arms);

for (j in 1:K) {
// everyone starts in state 1;
unalpha_tk[n][j] =log(pi0[j]) + log(empb[j, y[n]]);
}

gl=(X[n]>Xmean ? 0 : 1);
Xsum=Xsum+X[n];
Xmean=Xsum/(T[n]+1);


}else{
// for (t in 2:T) {;

//gain/ loss: it's a raw vector;
XD=[1, gl];
// computes running average;
ew1=ew[y[n-1]];
ew[y[n-1]]= ew[y[n-1]]+1;
W_Average[y[n-1]]=(ew1*W_Average[y[n-1]]+X[n-1])/ew[y[n-1]];

for(arm in 1:N_arms)
{//State 1 - random: keep empb[1];
empb[1, arm]=log(0.333333333333333333333333333);
// State 2 - exploitation;
empb[2, arm]=categorical_logit_lpmf(arm|W_Average);
// State 3 - inertia;
empb[3, arm]=log(arm==y[n-1] ? 0.99995 : 0.000025);}

for (j in 1:K) { // j = current (t)
for (i in 1:K) { // i = previous (t-1)
// Murphy (2012) Eq. 17.48
// belief state + transition prob + local evidence at t
accumulator[i] = unalpha_tk[n-1, i]+categorical_logit_lpmf(z[j]|to_vector(XD*beta[i,ID[n]]')) + empb[j, y[n]];
}
unalpha_tk[n, j] = log_sum_exp(accumulator);
}

gl=(X[n]>Xmean ? 0 : 1);
Xsum=Xsum+X[n];
Xmean=Xsum/(T[n]+1);

//}
}

if(lastT[n]==1)
{unalpha_Tkn[ID[n]]=unalpha_tk[n];}
} // Forward
}

model {
to_vector(gamma) ~ normal(0, 1);
to_vector(betaD)~normal(0,1);
L_Omega~lkj_corr_cholesky(2);
tau~exponential(1);
to_vector(alpha)~normal(0, 1);

for (i in 1:H)
target += log_sum_exp(unalpha_Tkn[i]); // Note: update based only on last unalpha_tk
}

generated quantities{
vector[K] alpha_tk[N];

{ // Forward algortihm
for (n in 1:N)
alpha_tk[n] = softmax(unalpha_tk[n]);
} // Forward

}
"

#* EWA model  ----
ewa_only = "
data {
int<lower=1> N; // Observations
int<lower=1> N_arms; // Alternatives
int<lower=1> H; // Players
int<lower=1> nvar_ind; // number of parameters
int<lower=1, upper=N_arms> y[N]; // Choice Indicator
int T[N]; // Rounds
int<lower=1> ID[N];              // vector of individual index
vector[N_arms] prior; // prior knowledge =50
real X[N]; // stacked observations
int z[N_arms];
real<lower=0, upper=10> N0;
int <lower=1> ndem;
matrix[H, ndem] u;
}

parameters {
matrix[nvar_ind, H] alpha; // nvar*H parameter matrix
matrix[ndem, nvar_ind] gamma; // delta
cholesky_factor_corr[nvar_ind] L_Omega; // Vbeta- prior correlation
vector<lower=0>[nvar_ind] tau;
}

transformed parameters {

real<lower=0, upper=1> lambda[H]; // delta
real<lower=0, upper=1> rho[H]; // delta
real<lower=0, upper=1> phi[H]; // delta

matrix[H, nvar_ind] delta;
matrix[H, nvar_ind] Vdelta_reparametrized;

Vdelta_reparametrized = (diag_pre_multiply(tau, L_Omega)*alpha)';
delta=u*gamma+Vdelta_reparametrized;

for (h in 1:H)
{
  lambda[h]=inv_logit(delta[h,1]);
  rho[h]=inv_logit(delta[h,2]);
  phi[h]=inv_logit(delta[h,3]);
}

}

model {
vector[N_arms] W_Average;
vector[N_arms] ew;
real ew1;

to_vector(gamma) ~ normal(0, 1);
L_Omega~lkj_corr_cholesky(2);
tau~exponential(1);
to_vector(alpha)~normal(0, 1);

for (n in 1:N)
{ 
if(T[n]==1){
ew=rep_vector(N0, N_arms);
W_Average=prior;

y[n]~categorical_logit(lambda[ID[n]]*W_Average);

  }else{
  ew1=ew[y[n-1]];
  ew[y[n-1]]= rho[ID[n]]*ew[y[n-1]]+1;
  W_Average[y[n-1]]=(phi[ID[n]]*ew1*W_Average[y[n-1]]+X[n-1])/ew[y[n-1]];
  
  y[n]~categorical_logit(lambda[ID[n]]*W_Average);
  }
}

}

generated quantities{
corr_matrix[nvar_ind] Omega;

vector<lower=0, upper=1>[N_arms] pb_g[N];  // choice probability: pb of 1 or 0, given state, at each obs.
real log_lik[H]; 
real y_rep[N]; 
vector[N_arms] W_Averageg;
vector[N_arms] ewg;
real ew1g;

Omega = L_Omega * L_Omega';

for (n in 1:N)
{ 
if(T[n]==1){
log_lik[ID[n]] = 0;
ewg=rep_vector(N0, N_arms);
W_Averageg=prior;

for(arm in 1:N_arms)
pb_g[n,arm]=exp(categorical_logit_lpmf(arm | lambda[ID[n]]*W_Averageg));

y_rep[n]=categorical_logit_rng(lambda[ID[n]]*W_Averageg);
log_lik[ID[n]] = log_lik[ID[n]] + categorical_logit_lpmf(y[n] | lambda[ID[n]]*W_Averageg);

}else{

ew1g=ewg[y[n-1]];
ewg[y[n-1]]= rho[ID[n]]*ewg[y[n-1]]+1;
W_Averageg[y[n-1]]=(phi[ID[n]]*ew1g*W_Averageg[y[n-1]]+X[n-1])/ewg[y[n-1]];

for(arm in 1:N_arms)
pb_g[n,arm]=exp(categorical_logit_lpmf(arm | lambda[ID[n]]*W_Averageg));

y_rep[n]=categorical_logit_rng(lambda[ID[n]]*W_Averageg);
log_lik[ID[n]] = log_lik[ID[n]] + categorical_logit_lpmf(y[n] | lambda[ID[n]]*W_Averageg);
}
}
}
"

#* EWA model for OOS ----
# excludes generated quantities
ewa_only_oos = "
data {
int<lower=1> N; // Observations
int<lower=1> N_arms; // Alternatives
int<lower=1> H; // Players
int<lower=1> nvar_ind; // number of parameters
int<lower=1, upper=N_arms> y[N]; // Choice Indicator
int T[N]; // Rounds
int<lower=1> ID[N];              // vector of individual index
vector[N_arms] prior; // prior knowledge =50
real X[N]; // stacked observations
int z[N_arms];
real<lower=0, upper=10> N0;
int <lower=1> ndem;
matrix[H, ndem] u;
}

parameters {
matrix[nvar_ind, H] alpha; // nvar*H parameter matrix
matrix[ndem, nvar_ind] gamma; // delta
cholesky_factor_corr[nvar_ind] L_Omega; // Vbeta- prior correlation
vector<lower=0>[nvar_ind] tau;
}

transformed parameters {

real<lower=0, upper=1> lambda[H]; // delta
real<lower=0, upper=1> rho[H]; // delta
real<lower=0, upper=1> phi[H]; // delta

matrix[H, nvar_ind] delta;
matrix[H, nvar_ind] Vdelta_reparametrized;

Vdelta_reparametrized = (diag_pre_multiply(tau, L_Omega)*alpha)';
delta=u*gamma+Vdelta_reparametrized;

for (h in 1:H)
{
  lambda[h]=inv_logit(delta[h,1]);
  rho[h]=inv_logit(delta[h,2]);
  phi[h]=inv_logit(delta[h,3]);
}

}

model {
vector[N_arms] W_Average;
vector[N_arms] ew;
real ew1;

to_vector(gamma) ~ normal(0, 1);
L_Omega~lkj_corr_cholesky(2);
tau~exponential(1);
to_vector(alpha)~normal(0, 1);

for (n in 1:N)
{ 
if(T[n]==1){
ew=rep_vector(N0, N_arms);
W_Average=prior;

y[n]~categorical_logit(lambda[ID[n]]*W_Average);

  }else{
  ew1=ew[y[n-1]];
  ew[y[n-1]]= rho[ID[n]]*ew[y[n-1]]+1;
  W_Average[y[n-1]]=(phi[ID[n]]*ew1*W_Average[y[n-1]]+X[n-1])/ew[y[n-1]];
  
  y[n]~categorical_logit(lambda[ID[n]]*W_Average);
  }
}
}
"

## MODEL COMPARISON FUNCTIONS -----
#* In-sample fit all EEI models ----
InSample_stats<-function(stfit, dataset){
y=pull(dataset, picks)
## filtered state probabilities
alpha_tk <- rstan::extract(stfit, pars = 'alpha_tk')[[1]]
## choice probs
empb_g <- rstan::extract(stfit, pars = 'empb_n')[[1]]
N=nrow(dataset)
niter=length(alpha_tk[,1,1])
J=length(unique(y))
Zpred=yrep=pb_mse=matrix(, nrow=niter, ncol=N)
mse_iter=hr_iter=rep(0, niter)

for (iter in 1:niter){

  ziter=NULL
  for (n in 1:N){
    ## state draws
    z_draw = sample(x = 1:K, size = 1, prob=alpha_tk[iter, n, ])
    pb=empb_g[iter, n, z_draw, ]
    yrep[iter, n]=sample(1:J, 1, pb, replace = T)
    pb_mse[iter, n]=pb[y[n]]
    ziter=c(ziter, z_draw)
  }
  Zpred[iter, ]=ziter
  hr_iter[iter]=sum(ifelse(yrep[iter,]==y, 1,0))/N
  mse_iter[iter]=mean((1-pb_mse[iter,])^2)
}

mse=mean(mse_iter)
hr=mean(hr_iter)

ll=summary(stfit, pars = c("lp__"), probs=c(0.5))$summary[1]
waic=waic(extract_log_lik(stfit))
rm(alpha_tk)
return(list(ll, waic$estimates[3], hr, mse, yrep, Zpred))
}

#* In-sample fit for EWA ----
# no states here
InSample_EWA<-function(stfit, dataset){
  # MSE for EWA 
  pbg=as.matrix(stfit, pars=c("pb_g"))
  pbg_med=matrix(apply(pbg, 2, median), ncol=N_arms)
  y=dataset$picks
  dummy_y=dummy(y)
  pb_chosen=rowSums(pbg_med*dummy_y)
  mse=mean((1-pb_chosen)^2)
  # Hit rate for EWA 
  y_rep=as.matrix(stfit, pars=c("y_rep"))
  niter=nrow(y_rep)
  hr_iter=rep(0, niter)
  for (iter in 1:niter){
    hr_iter[iter]=sum(ifelse(y_rep[iter,]==y, 1,0))/(Nobs*H)
  }
  hr=mean(hr_iter)
  
  ll=summary(stfit, pars = c("lp__"), probs=c(0.5))$summary[1]
  waic=waic(extract_log_lik(stfit))
  return(c(ll, waic$estimates[3], hr, mse))
}

## Insample sims----
InSample_sims<-function(stfit, dataset){
  y=pull(dataset, y)
  ## filtered state probabilities
  alpha_tk <- rstan::extract(stfit, pars = 'alpha_tk')[[1]]
  ## choice probs
  empb_g <- rstan::extract(stfit, pars = 'empb_n')[[1]]
  N=nrow(dataset)
  niter=length(alpha_tk[,1,1])
  J=length(unique(y))
  Zpred=yrep=pb_mse=matrix(, nrow=niter, ncol=N)
  mse_iter=hr_iter=rep(0, niter)
  
  for (iter in 1:niter){
    ziter=NULL
    for (n in 1:N){
      ## state draws
      z_draw = sample(x = 1:K, size = 1, prob=alpha_tk[iter, n, ])
      pb=empb_g[iter, n, z_draw, ]
      yrep[iter, n]=sample(1:J, 1, pb, replace = T)
      pb_mse[iter, n]=pb[y[n]]
      ziter=c(ziter, z_draw)
    }
    
    Zpred[iter, ]=ziter
    hr_iter[iter]=sum(ifelse(yrep[iter,]==y, 1,0))/N
    mse_iter[iter]=mean((1-pb_mse[iter,])^2)
  }
  
  mse=mean(mse_iter)
  hr=mean(hr_iter)
  
  ll=summary(stfit, pars = c("lp__"), probs=c(0.5))$summary[1]
  waic=waic(extract_log_lik(stfit))
  rm(alpha_tk)
  return(list(ll, waic$estimates[3], hr, mse, yrep, Zpred))
  
}

#* Out-of-sample predictions ----
## Use stancode without generated quantities to save space
##** EWA model ----
#*** Temporal forecasting ----
# K-from, H - ind, K - to, D - number of covariates
out_of_sample_ewa <- function(oos_t, stfit, dataset){
 
  lambda_draw <- as.matrix(stfit, pars = c("lambda"))
  rho_draw <- as.matrix(stfit, pars = c("rho"))
  phi_draw <- as.matrix(stfit, pars = c("phi"))
  
  X=pull(roundsData, results)
  y=pull(roundsData, picks)
  Niter=nrow(lambda_draw)
  Yoos_iter=Pred_prob_iter=NULL
  hr_iter=mse_iter=rep(0, Niter)
  
  for (iter in 1:Niter){
    # iter=1
    y_oos_pred= pred_probs =NULL
    
    for (h in 1:H){
     
      lambda = lambda_draw[iter, h]
      rho=rho_draw[iter, h]
      phi=phi_draw[iter, h]
      
      ## assume I have oos_t=21 to 100, only take the corresponding Xs
      Xh=X[((h-1)*Nobs+1):(h*Nobs)]
      yh=y[((h-1)*Nobs+1):(h*Nobs)]
       
      ew=rep(N0, N_arms);
      W_Average=rep(prior, N_arms);
      for (t in 2:oos_t) {
        ew1=ew[yh[t-1]];
        ew[yh[t-1]]=rho*ew[yh[t-1]]+1;
        W_Average[yh[t-1]]=(phi*ew1*W_Average[yh[t-1]]+Xh[t-1])/ew[yh[t-1]];
      }
      
      ypred=emprobs=NULL
      for (t in (oos_t+1):Nobs) {
            
        ## upate still based on actual choices
        ew1=ew[yh[t-1]];
        ew[yh[t-1]]=rho*ew[yh[t-1]]+1;
        W_Average[yh[t-1]]=(phi*ew1*W_Average[yh[t-1]]+Xh[t-1])/ew[yh[t-1]];
        
        emprob=softmax(lambda*W_Average);
  
        ysim=sample(1:N_arms, size = 1, prob = emprob)
        
        ypred=c(ypred, ysim)
        emprobs=c(emprobs, emprob[yh[t]])
      }
      y_oos_pred=c(y_oos_pred, ypred)
      pred_probs=c(pred_probs, emprobs)
    }
    
    Yoos_iter=rbind(Yoos_iter, y_oos_pred)
    Pred_prob_iter=rbind(Pred_prob_iter, pred_probs)
    
    hr_vec=ifelse(y_oos_pred==dataset$picks, 1, 0)
    hr_iter[iter]=sum(hr_vec)/nrow(dataset)
    mse_iter[iter]=mean((1-pred_probs)^2)
  
  }
  return(list(hr_iter, mse_iter, Yoos_iter, Pred_prob_iter))
}

##*** Coss-sectional validation ----
z_draw<-function(beta, XD){
  Qij <- softmax(t(XD)%*% t(beta) )
  z_draw <- sample(x = 1:K, size = 1, prob = Qij)
  return(z_draw)
}
# K-from, H - ind, K - to, D - number of covariates
out_of_sample_ewa_only_across_subjects <- function(stfit, pred_df, est_df, inddifFull){
  pred_data=pred_df %>% 
    arrange(usercode, Rounds)
  
  pred_inddif=inddifFull %>% 
    filter(!(user_id %in% est_df$usercode)) %>% 
    arrange(user_id)
  
  if (INDDIFF) {inddifDataset=as.matrix(pred_inddif %>% dplyr::select(-user_id))
  }else{ inddifDataset=as.matrix(pred_inddif %>% dplyr::select(iota)) } 
  
  ## compute parameter estimates over iterations = f(ind psych profile) 
  gamma_draw <- as.matrix(stfit, pars = c("gamma") )
  
  Niter=nrow(gamma_draw)
  pred_data_with_oos=pred_data
  hr_iter=mse_iter=rep(0, Niter)
  Pred_prob_iter=Ypred_iter=matrix(, nrow=nrow(pred_data), ncol=Niter)
  
  for (iter in 1:Niter){

    gamma=matrix(gamma_draw[iter, ], ncol=nvarWA)
    y_oos_pred= NULL
    pred_probs = NULL
    All_pred_probs_ychosen=NULL
    
    for (h in 1:length(unique(pred_data$pred_ID))){

      ## each individual in the prediction data
      delta=t(inddifDataset[h, ]) %*% gamma
      
      lambda = inv_logit(delta[1])
      rho=inv_logit(delta[2])
      phi=inv_logit(delta[3])
      
      X=pull(pred_data %>% filter(pred_ID==h), results)
      y=pull(pred_data %>% filter(pred_ID==h), picks)
      
      ## given subjects' actual path (and rewards) up to t,
      ## and the parameters estimated out-of-sample,
      ## how likely are they to choose y?
      ew=rep(N0, N_arms);
      W_Average=rep(prior, N_arms);
      ## draw a choice from p(y|explore)
      emprobs=matrix(, ncol=N_arms, nrow=Nobs)
      emprobs[1, ]=c(0.333333, .333333, 0.333334);
      ypred=sample(1:N_arms, size = 1, prob = emprobs[1, ])
      pred_prob_ychosen=emprobs[1, ypred]
      
      for (t in 2:Nobs) {
       
        ## upate still based on actual choices
        ew1=ew[y[t-1]];
        ew[y[t-1]]=rho*ew[y[t-1]]+1;
        W_Average[y[t-1]]=(phi*ew1*W_Average[y[t-1]]+X[t-1])/ew[y[t-1]];
        
        ## draw choice
        emprob=softmax(lambda*W_Average);
        
        ysim=sample(1:N_arms, size = 1, prob = emprob)
        
        ypred=c(ypred, ysim)
        emprobs[t, ]=emprob;
        # for mse 
        pred_prob_ychosen=c(pred_prob_ychosen, emprob[y[t]])
      }

      y_oos_pred=c(y_oos_pred, ypred)
      All_pred_probs_ychosen=c(All_pred_probs_ychosen, pred_prob_ychosen)
    }
    
    Ypred_iter[, iter]= y_oos_pred
    Pred_prob_iter[, iter]= All_pred_probs_ychosen
    
    hr_vec=ifelse(y_oos_pred==pred_data$picks, 1, 0)
    hr_iter[iter]=sum(hr_vec)/nrow(pred_df)
    mse_iter[iter]=mean((1-All_pred_probs_ychosen)^2)
  }
  
  Ypred_iter=as_tibble(Ypred_iter)
  colnames(Ypred_iter)=paste0("ypred_it", 1:Niter)
  
  pred_data_with_oos = pred_data %>% 
     bind_cols(Ypred_iter)
  return(list(hr_iter, mse_iter, pred_data_with_oos))
}

##** EEI model ----
#*** Temporal forecasting ----
# K-from, H - ind, K - to, D - number of covariates
out_of_sample_eei_no_ewa <- function(oos_t, stfit, dataset){
  alpha_tk <- rstan::extract(stfit, pars = 'alpha_tk')[[1]]
  ## state draws
  zstar_drawE = apply(alpha_tk, c(1, 2), which.is.max)
  
  beta_draw <- as.matrix(stfit, pars = c("beta"))
  
  X=pull(roundsData, results)
  y=pull(roundsData, picks)
  Niter=nrow(zstar_drawE)
  Zoos_iter=Yoos_iter=Pred_prob_iter=NULL
  hr_iter=mse_iter=rep(0, Niter)
  
  for (iter in 1:Niter){
    
    beta_all=array(beta_draw[iter, ], dim=c(K, H, K, D))
    zind_oos=y_oos_pred= pred_probs =NULL
    
    for (h in 1:H){
      
      ## individual-specific Xs and ys
      Xh=X[((h-1)*Nobs+1):(h*Nobs)]
      yh=y[((h-1)*Nobs+1):(h*Nobs)]
      Xmean=mean(c(prior, Xh[1:(oos_t-1)]))
      gl=ifelse(Xh[oos_t]>Xmean, 0, 1);
      XD=c(1, gl);
      zind=zstar_drawE[iter, oos_t*h] #estimated state at the last est_obs
      
      beta=beta_all[zind, h, , ]
      ew=rep(N0, N_arms);
      W_Average=rep(prior, N_arms);
      for (t in 2:oos_t) {
        ew1=ew[yh[t-1]];
        ew[yh[t-1]]=ew[yh[t-1]]+1;
        W_Average[yh[t-1]]=(ew1*W_Average[yh[t-1]]+Xh[t-1])/ew[yh[t-1]];
      }
      
      zpred=ypred=emprobs=NULL
      for (t in (oos_t+1):Nobs) {
        ## Draw state 
        zind <- z_draw(beta, XD)
        ## in next iteration, I will draw a state using betas from the current state
        beta=beta_all[zind, h, , ]
        
        ## upate still based on actual choices
        ew1=ew[yh[t-1]];
        ew[yh[t-1]]=ew[yh[t-1]]+1;
        W_Average[yh[t-1]]=(ew1*W_Average[yh[t-1]]+Xh[t-1])/ew[yh[t-1]];
        
        ## draw choice given state
        if(zind==1) { #State 1 - exploration
          emprob=softmax(rep(1,N_arms) )
        }else if (zind==2) { #State 2 - exploitation;
          emprob=softmax(W_Average);
        }else{ # State 3 - inertia;
          emprob=rep(0.000025, N_arms);
          emprob[yh[t-1]]=0.99995
        }
        
        ysim=sample(1:N_arms, size = 1, prob = emprob)
        Xmean=mean(c(prior, Xh[1:(t-1)]))
        gl=ifelse(Xh[t]>Xmean,0, 1);
        XD=c(1, gl);
        zpred=c(zpred, zind)
        ypred=c(ypred, ysim)
        emprobs=c(emprobs, emprob[yh[t]])
      }
      zind_oos=c(zind_oos, zpred)
      y_oos_pred=c(y_oos_pred, ypred)
      pred_probs=c(pred_probs, emprobs)
    }
    
    Yoos_iter=rbind(Yoos_iter, y_oos_pred)
    Zoos_iter=rbind(Zoos_iter, zind_oos)
    Pred_prob_iter=rbind(Pred_prob_iter, pred_probs)
    
    hr_vec=ifelse(y_oos_pred==dataset$picks, 1, 0)
    hr_iter[iter]=sum(hr_vec)/nrow(dataset)
    mse_iter[iter]=mean((1-pred_probs)^2)
    
  }
  return(list(hr_iter, mse_iter, Yoos_iter, Zoos_iter, Pred_prob_iter))
}

##*** Coss-sectional validation ----
out_of_sample_eei_no_ewa_across_subjects <- function(stfit, pred_df, est_df, inddifFull){
  pred_data=pred_df %>% 
    arrange(usercode, Rounds)
  
  pred_inddif=inddifFull %>% 
    filter(!(user_id %in% est_df$usercode)) %>% 
    arrange(user_id)
  
  if (INDDIFF) {inddifDataset=as.matrix(pred_inddif %>% dplyr::select(-user_id))
  }else{ inddifDataset=as.matrix(pred_inddif %>% dplyr::select(iota)) } 
  ## compute parameter estimates over iterations = f(ind psych profile) 
  gamma_draw <- as.matrix(stfit, pars = c("gamma") )
  
  ## order: betaD 11, 12, 21, 22, 31, 32
  betaD_draw <- as.matrix(stfit, pars = c("betaD"))
 
  Niter=nrow(gamma_draw)
  pred_data_with_oos=pred_data
  hr_iter=mse_iter=rep(0, Niter)
  Zpred_iter=Pred_prob_iter=Ypred_iter=matrix(, nrow=nrow(pred_data), ncol=Niter)
  
  for (iter in 1:Niter){
    # iter=1
    gamma=matrix(gamma_draw[iter, ], ncol=(nvarHMM) )
    betaD=betaD_draw[iter, ]
     
    zind_pred=y_oos_pred= NULL
    pred_probs = NULL
    All_pred_probs_ychosen=NULL
    
    for (h in 1:length(unique(pred_data$pred_ID))){
      ## h=1
      ## each individual in the prediction data
      delta=t(inddifDataset[h, ]) %*% gamma
      # beta matrix: K - to, D- number of covariates, K-from state
      beta=array( , dim=c(K,D,K) )
      for (k in 1:K)
      {beta[,,k]= matrix(c(delta[((k-1)*(K-1)+1):(k*(K-1))], 0, betaD[((k-1)*(K-1)+1):(k*(K-1))], 0), ncol=D)};
      
      X=pull(pred_data %>% filter(pred_ID==h), results)
      y=pull(pred_data %>% filter(pred_ID==h), picks)
      
      ## given subjects' actual path (and rewards) up to t,
      ## and the parameters estimated out-of-sample,
      ## how likely are they to choose y?
      zind=gl=vector("numeric", Nobs)
      zind[1]= sample(x = 1:K, size = 1, prob = pi0)
      gl[1]=ifelse(X[1]>prior, 0, 1);
      
      ew=rep(N0, N_arms);
      W_Average=rep(prior, N_arms);
      ## draw a choice from p(y|explore)
      emprobs=matrix(, ncol=N_arms, nrow=Nobs)
      emprobs[1, ]=c(0.333333, .333333, 0.333334);
      ypred=sample(1:N_arms, size = 1, prob = emprobs[1, ])
      pred_prob_ychosen=emprobs[1, ypred]
      
      for (t in 2:Nobs) {
        # t=2
        ## Draw state 
        XD=c(1, gl[t-1]);
        zind[t] <- z_draw(beta[,,zind[t-1]], XD)
        
        ## upate still based on actual choices
        ew1=ew[y[t-1]];
        ew[y[t-1]]=ew[y[t-1]]+1;
        W_Average[y[t-1]]=(ew1*W_Average[y[t-1]]+X[t-1])/ew[y[t-1]];
        
        ## draw choice given state
        if(zind[t]==1) { #State 1 - exploration
          emprob=softmax(rep(1,N_arms) )
        }else if (zind[t]==2) { #State 2 - exploitation;
          emprob=softmax(W_Average);
        }else{ # State 3 - inertia;
          emprob=rep(0.000025, N_arms);
          emprob[y[t-1]]=0.99995
        }
        
        ysim=sample(1:N_arms, size = 1, prob = emprob)
        Xmean=mean(c(prior, X[1:(t-1)]))
        gl[t]=ifelse(X[t]>Xmean,0, 1);
        
        ypred=c(ypred, ysim)
        emprobs[t, ]=emprob;
        # for mse 
        pred_prob_ychosen=c(pred_prob_ychosen, emprob[y[t]])
      }
      
      zind_pred=c(zind_pred, zind)
      y_oos_pred=c(y_oos_pred, ypred)
      All_pred_probs_ychosen=c(All_pred_probs_ychosen, pred_prob_ychosen)
    }
    
    Zpred_iter[, iter]= zind_pred
    Ypred_iter[, iter]= y_oos_pred
    Pred_prob_iter[, iter]= All_pred_probs_ychosen
    
    hr_vec=ifelse(y_oos_pred==pred_data$picks, 1, 0)
    hr_iter[iter]=sum(hr_vec)/nrow(pred_df)
    mse_iter[iter]=mean((1-All_pred_probs_ychosen)^2)
  }
  
  Ypred_iter=as_tibble(Ypred_iter)
  colnames(Ypred_iter)=paste0("ypred_it", 1:Niter)

  pred_data_with_oos = pred_data_with_oos %>% 
    bind_cols(Ypred_iter)  

  return(list(hr_iter, mse_iter, Zpred_iter, pred_data_with_oos))
}

##** statEEI/EWA ---- 
# K-from, H - ind, K - to, D - number of covariates
#*** Temporal forecasting ----
out_of_sample_eei_stat <- function(oos_t, stfit, dataset){
    alpha_tk <- rstan::extract(stfit, pars = 'alpha_tk')[[1]]
    ## state draws
    zstar_drawE = apply(alpha_tk, c(1, 2), which.is.max)
    
    beta_draw <- as.matrix(stfit, pars = c("beta"))
    lambda_explore_draw <- as.matrix(stfit, pars = c("lambda_explore"))
    lambda_exploit_draw <- as.matrix(stfit, pars = c("lambda_exploit"))
    rho_draw <- as.matrix(stfit, pars = c("rho"))
    phi_draw <- as.matrix(stfit, pars = c("phi"))
    
    X=pull(roundsData, results)
    y=pull(roundsData, picks)
    Niter=length(lambda_explore_draw)
    Zoos_iter=Yoos_iter=Pred_prob_iter=NULL
    hr_iter=mse_iter=rep(0, Niter)
    
    for (iter in 1:Niter){
      
      beta_all=array(beta_draw[iter, ], dim=c(K, H, K))
      zind_oos=y_oos_pred= pred_probs =NULL
      
      for (h in 1:H){
        
        lambda_explore = lambda_explore_draw[iter]
        lambda_exploit = lambda_exploit_draw[iter, h]
        rho=rho_draw[iter, h]
        phi=phi_draw[iter, h]
        
        ## individual-specific Xs and ys
        Xh=X[((h-1)*Nobs+1):(h*Nobs)]
        yh=y[((h-1)*Nobs+1):(h*Nobs)]
        
        zind=zstar_drawE[iter, oos_t*h] #estimated state at the last est_obs
 
        beta=beta_all[zind, h, ]
        ew=rep(N0, N_arms);
        W_Average=rep(prior, N_arms);
        for (t in 2:oos_t) {
          ew1=ew[yh[t-1]];
          ew[yh[t-1]]=rho*ew[yh[t-1]]+1;
          W_Average[yh[t-1]]=(phi*ew1*W_Average[yh[t-1]]+Xh[t-1])/ew[yh[t-1]];
        }
        
        zpred=ypred=emprobs=NULL
        for (t in (oos_t+1):Nobs) {
          ## Draw state 
          zind <- z_draw(beta, c(1))
          beta=beta_all[zind, h, ]
          
          ## upate still based on actual choices
          ew1=ew[yh[t-1]];
          ew[yh[t-1]]=rho*ew[yh[t-1]]+1;
          W_Average[yh[t-1]]=(phi*ew1*W_Average[yh[t-1]]+Xh[t-1])/ew[yh[t-1]];
          
          ## draw choice given state
          if(zind==1) { #State 1 - exploration
            emprob=softmax(lambda_explore*W_Average)
          }else if (zind==2) { #State 2 - exploitation;
            emprob=softmax(lambda_exploit*W_Average);
          }else{ # State 3 - inertia;
            emprob=rep(0.000025, N_arms);
            emprob[yh[t-1]]=0.99995
          }
    
          ysim=sample(1:N_arms, size = 1, prob = emprob)
          zpred=c(zpred, zind)
          ypred=c(ypred, ysim)
          emprobs=c(emprobs, emprob[yh[t]])
        }
        zind_oos=c(zind_oos, zpred)
        y_oos_pred=c(y_oos_pred, ypred)
        pred_probs=c(pred_probs, emprobs)
      }
      
      Zoos_iter=rbind(Zoos_iter, zind_oos)
      Yoos_iter=rbind(Yoos_iter, y_oos_pred)
      Pred_prob_iter=rbind(Pred_prob_iter, pred_probs)
    
      hr_vec=ifelse(y_oos_pred==dataset$picks, 1, 0)
      hr_iter[iter]=sum(hr_vec)/nrow(dataset)
      mse_iter[iter]=mean((1-pred_probs)^2)
      
    }
    return(list(hr_iter, mse_iter, Yoos_iter, Zoos_iter, Pred_prob_iter))
}

##*** Coss-sectional validation ----
out_of_sample_eei_stat_ewa_across_subjects <- function(stfit, pred_df, est_df, inddifFull){
  pred_data=pred_df %>% 
    arrange(usercode, Rounds)
  
  pred_inddif=inddifFull %>% 
    filter(!(user_id %in% est_df$usercode)) %>% 
    arrange(user_id)
  
  if (INDDIFF) {inddifDataset=as.matrix(pred_inddif %>% dplyr::select(-user_id))
  }else{ inddifDataset=as.matrix(pred_inddif %>% dplyr::select(iota)) } 
  
  ## compute parameter estimates over iterations = f(ind psych profile) 
  gamma_draw <- as.matrix(stfit, pars = c("gamma") )
  
  lambda_explore_unt_draw <- as.matrix(stfit, pars = c("lambda_explore_unt"))
  
  Niter=length(lambda_explore_unt_draw)
  pred_data_with_oos=pred_data
  hr_iter=mse_iter=rep(0, Niter)
  Zpred_iter=Pred_prob_iter=Ypred_iter=matrix(, nrow=nrow(pred_data), ncol=Niter)
  
  for (iter in 1:Niter){
    
    gamma=matrix(gamma_draw[iter, ], ncol=(nvarHMM+nvarWA))
    
    lambda_explore=inv_logit(lambda_explore_unt_draw[iter, ])
    
    zind_pred=y_oos_pred= NULL
    pred_probs = NULL
    All_pred_probs_ychosen=NULL
    
    for (h in 1:length(unique(pred_data$pred_ID))){
      ## each individual in the prediction data
      delta=t(inddifDataset[h, ]) %*% gamma
      # beta matrix: K - to, K-from state
      ## D- number of covariates not necessary
      beta=matrix( , ncol=K, nrow=K)
      for (k in 1:K)
      {beta[,k]= matrix(c(delta[((k-1)*(K-1)+1):(k*(K-1))], 0), ncol=K)};
      
      lambda_exploit_unt=lambda_explore_unt_draw[iter, ]+exp(delta[K*(K-1)+1])
      if(lambda_exploit_unt<(-50)) {lambda_exploit = 0
      } else if (lambda_exploit_unt>(50)) {
        lambda_exploit = 1
      }else{
        lambda_exploit = inv_logit(lambda_exploit_unt)
      }
      
      if(delta[K*(K-1)+2]<(-50)) {rho = 0
      } else if (delta[K*(K-1)+2]>(50)) {
        rho = 1
      }else{
        rho=inv_logit(delta[K*(K-1)+2])
      }
      
      if(delta[K*(K-1)+3]<(-50)) {phi = 0
      } else if (delta[K*(K-1)+3]>(50)) {
        phi = 1
      }else{
        phi=inv_logit(delta[K*(K-1)+3])
      }
      
      X=pull(pred_data %>% filter(pred_ID==h), results)
      y=pull(pred_data %>% filter(pred_ID==h), picks)
      
      ## given subjects' actual path (and rewards) up to t,
      ## and the parameters estimated out-of-sample,
      ## how likely are they to choose y?
      zind=gl=vector("numeric", Nobs)
      zind[1]= sample(x = 1:K, size = 1, prob = pi0)
      gl[1]=ifelse(X[1]>prior, 0, 1);
      
      ew=rep(N0, N_arms);
      W_Average=rep(prior, N_arms);
      ## draw a choice from p(y|explore)
      emprobs=matrix(, ncol=N_arms, nrow=Nobs)
      emprobs[1, ]=c(0.333333, .333333, 0.333334);
      ypred=sample(1:N_arms, size = 1, prob = emprobs[1, ])
      pred_prob_ychosen=emprobs[1, ypred]
      
      for (t in 2:Nobs) {
        ## Draw state
        zind[t] <- z_draw(beta[,zind[t-1]], c(1))
        ## upate still based on actual choices
        ew1=ew[y[t-1]];
        ew[y[t-1]]=rho*ew[y[t-1]]+1;
        W_Average[y[t-1]]=(phi*ew1*W_Average[y[t-1]]+X[t-1])/ew[y[t-1]];
        
        ## draw choice given state
        if(zind[t]==1) { #State 1 - exploration
          emprob=softmax(lambda_explore*W_Average)
        }else if (zind[t]==2) { #State 2 - exploitation;
          emprob=softmax(lambda_exploit*W_Average);
        }else{ # State 3 - inertia;
          emprob=rep(0.000025, N_arms);
          emprob[y[t-1]]=0.99995
        }
      
        ysim=sample(1:N_arms, size = 1, prob = emprob)
        Xmean=mean(c(prior, X[1:(t-1)]))
        gl[t]=ifelse(X[t]>Xmean,0, 1);
        
        ypred=c(ypred, ysim)
        emprobs[t, ]=emprob;
        # for mse 
        pred_prob_ychosen=c(pred_prob_ychosen, emprob[y[t]])
      }
      
      zind_pred=c(zind_pred, zind)
      y_oos_pred=c(y_oos_pred, ypred)
      All_pred_probs_ychosen=c(All_pred_probs_ychosen, pred_prob_ychosen)
    }
    
    Zpred_iter[, iter]= zind_pred
    Ypred_iter[, iter]= y_oos_pred
    Pred_prob_iter[, iter]= All_pred_probs_ychosen
    
    hr_vec=ifelse(y_oos_pred==pred_data$picks, 1, 0)
    hr_iter[iter]=sum(hr_vec)/nrow(pred_df)
    mse_iter[iter]=mean((1-All_pred_probs_ychosen)^2)
  }
  
  Ypred_iter=as_tibble(Ypred_iter)
  colnames(Ypred_iter)=paste0("ypred_it", 1:Niter)

  pred_data_with_oos = pred_data %>% 
    bind_cols(Ypred_iter)

  return(list(hr_iter, mse_iter, Zpred_iter, pred_data_with_oos))
}


##** EEI/EWA, EEI/EWA no psychVars and EE/EWA ----
#*** Temporal forecasting ----
# K-from, H - ind, K - to, D - number of covariates
out_of_sample_predictions <- function(oos_t, stfit, dataset){
  alpha_tk <- rstan::extract(stfit, pars = 'alpha_tk')[[1]]
  ## state draws
  zstar_drawE = apply(alpha_tk, c(1, 2), which.is.max)

  beta_draw <- as.matrix(stfit, pars = c("beta"))
  lambda_explore_draw <- as.matrix(stfit, pars = c("lambda_explore"))
  lambda_exploit_draw <- as.matrix(stfit, pars = c("lambda_exploit"))
  rho_draw <- as.matrix(stfit, pars = c("rho"))
  phi_draw <- as.matrix(stfit, pars = c("phi"))

  X=pull(roundsData, results)
  y=pull(roundsData, picks)
  Niter=length(lambda_explore_draw)
  Zoos_iter=Yoos_iter=Pred_prob_iter=NULL
  hr_iter=mse_iter=rep(0, Niter)
  
for (iter in 1:Niter){

beta_all=array(beta_draw[iter, ], dim=c(K, H, K, D))
zind_oos=y_oos_pred= pred_probs =NULL

for (h in 1:H){

  lambda_explore = lambda_explore_draw[iter]
  lambda_exploit = lambda_exploit_draw[iter, h]
  rho=rho_draw[iter, h]
  phi=phi_draw[iter, h]

  ## individual-specific Xs and ys
  Xh=X[((h-1)*Nobs+1):(h*Nobs)]
  yh=y[((h-1)*Nobs+1):(h*Nobs)]
  Xmean=mean(c(prior, Xh[1:(oos_t-1)]))
  gl=ifelse(Xh[oos_t]>Xmean, 0, 1);
  XD=c(1, gl);
  zind=zstar_drawE[iter, oos_t*h] #estimated state at the last est_obs
  beta=beta_all[zind, h, , ]
  
  ew=rep(N0, N_arms);
  W_Average=rep(prior, N_arms);
  for (t in 2:oos_t) {
  ew1=ew[yh[t-1]];
  ew[yh[t-1]]=rho*ew[yh[t-1]]+1;
  W_Average[yh[t-1]]=(phi*ew1*W_Average[yh[t-1]]+Xh[t-1])/ew[yh[t-1]];
  }
  
  zpred=ypred=emprobs=NULL
  for (t in (oos_t+1):Nobs) {
    ## Draw state 
    zind <- z_draw(beta, XD)
    ## in next iteration, I will draw a state using betas from the current state
    beta=beta_all[zind, h, , ]

    ## upate still based on actual choices
    ew1=ew[yh[t-1]];
    ew[yh[t-1]]=rho*ew[yh[t-1]]+1;
    W_Average[yh[t-1]]=(phi*ew1*W_Average[yh[t-1]]+Xh[t-1])/ew[yh[t-1]];

    ## draw choice given state
    if(zind==1) { #State 1 - exploration
      emprob=softmax(lambda_explore*W_Average)
    }else if (zind==2) { #State 2 - exploitation;
      emprob=softmax(lambda_exploit*W_Average);
    }else{ # State 3 - inertia;
      emprob=rep(0.000025, N_arms);
      emprob[yh[t-1]]=0.99995
    }
    
    ysim=sample(1:N_arms, size = 1, prob = emprob)
    Xmean=mean(c(prior, Xh[1:(t-1)]))
    gl=ifelse(Xh[t]>Xmean,0, 1);
    XD=c(1, gl);
    zpred=c(zpred, zind)
    ypred=c(ypred, ysim)
    emprobs=c(emprobs, emprob[yh[t]])
  }
  zind_oos=c(zind_oos, zpred)
  y_oos_pred=c(y_oos_pred, ypred)
  pred_probs=c(pred_probs, emprobs)
}

Yoos_iter=rbind(Yoos_iter, y_oos_pred)
Zoos_iter=rbind(Zoos_iter, zind_oos)
Pred_prob_iter=rbind(Pred_prob_iter, pred_probs)

hr_vec=ifelse(y_oos_pred==dataset$picks, 1, 0)
hr_iter[iter]=sum(hr_vec)/nrow(dataset)
mse_iter[iter]=mean((1-pred_probs)^2)
                         
}
  return(list(hr_iter, mse_iter, Yoos_iter, Zoos_iter, Pred_prob_iter))
}

##*** Coss-sectional validation ----
out_of_sample_predictions_across_subjects <- function(stfit, pred_df, est_df, inddifFull){
  pred_data=pred_df %>% 
    arrange(usercode, Rounds)
  
  pred_inddif=inddifFull %>% 
    filter(!(user_id %in% est_df$usercode)) %>% 
    arrange(user_id)
  
  if (INDDIFF) {inddifDataset=as.matrix(pred_inddif %>% dplyr::select(-user_id))
  }else{ inddifDataset=as.matrix(pred_inddif %>% dplyr::select(iota)) } 
  
  ## compute parameter estimates over iterations = f(ind psych profile) 
  gamma_draw <- as.matrix(stfit, pars = c("gamma") )
  
  lambda_explore_unt_draw <- as.matrix(stfit, pars = c("lambda_explore_unt"))
  ## order: betaD 11, 12, 21, 22, 31, 32
  betaD_draw <- as.matrix(stfit, pars = c("betaD"))
  Niter=length(lambda_explore_unt_draw)
  pred_data_with_oos=pred_data
  hr_iter=mse_iter=rep(0, Niter)
  Zpred_iter=Pred_prob_iter=Ypred_iter=matrix(, nrow=nrow(pred_data), ncol=Niter)
  
  for (iter in 1:Niter){
  # iter=1
  gamma=matrix(gamma_draw[iter, ], ncol=(nvarHMM+nvarWA))
  betaD= betaD_draw[iter, ]
  lambda_explore_unt=summary(stfit, pars = c("lambda_explore_unt"))$summary[,1]
  lambda_explore= inv_logit(lambda_explore_unt_draw[iter, ]) 
  
  y_oos_pred= NULL
  pred_probs = NULL
  All_pred_probs_ychosen=NULL
  zind_pred=NULL
  for (h in 1:length(unique(pred_data$pred_ID))){
      ## each individual in the prediction data
      delta=t(inddifDataset[h, ]) %*% gamma
       # beta matrix: K - to, D- number of covariates, K-from state
      beta=array( , dim=c(K,D,K) )
      for (k in 1:K)
      {beta[,,k]= matrix(c(delta[((k-1)*(K-1)+1):(k*(K-1))], 0, betaD[((k-1)*(K-1)+1):(k*(K-1))], 0), ncol=D)};
      
      lambda_exploit_unt=lambda_explore_unt_draw[iter, ]+exp(delta[K*(K-1)+1])
      
      if(lambda_exploit_unt<(-50)) {lambda_exploit = 0
      } else if (lambda_exploit_unt>(50)) {
        lambda_exploit = 1
      }else{
        lambda_exploit = inv_logit(lambda_exploit_unt)
      }
      
      if(delta[K*(K-1)+2]<(-50)) {rho = 0
      } else if (delta[K*(K-1)+2]>(50)) {
        rho = 1
      }else{
        rho=inv_logit(delta[K*(K-1)+2])
      }
      
      if(delta[K*(K-1)+3]<(-50)) {phi = 0
      } else if (delta[K*(K-1)+3]>(50)) {
        phi = 1
      }else{
        phi=inv_logit(delta[K*(K-1)+3])
      }

      X=pull(pred_data %>% filter(pred_ID==h), results)
      y=pull(pred_data %>% filter(pred_ID==h), picks)
      
      ## given subjects' actual path (and rewards) up to t,
      ## and the parameters estimated out-of-sample,
      ## how likely are they to choose y?
      zind=gl=vector("numeric", Nobs)
      zind[1]= sample(x = 1:K, size = 1, prob = pi0)
      gl[1]=ifelse(X[1]>prior, 0, 1);
      
      ew=rep(N0, N_arms);
      W_Average=rep(prior, N_arms);
      ## draw a choice from p(y|explore)
      emprobs=matrix(, ncol=N_arms, nrow=Nobs)
      emprobs[1, ]=c(0.333333, .333333, 0.333334);
      ypred=sample(1:N_arms, size = 1, prob = emprobs[1, ])
      pred_prob_ychosen=emprobs[1, ypred]
        
      for (t in 2:Nobs) {
        ## Draw state 
        XD=c(1, gl[t-1]);
        zind[t] <- z_draw(beta[,,zind[t-1]], XD)
        ## upate still based on actual choices
        ew1=ew[y[t-1]];
        ew[y[t-1]]=rho*ew[y[t-1]]+1;
        W_Average[y[t-1]]=(phi*ew1*W_Average[y[t-1]]+X[t-1])/ew[y[t-1]];
        
        ## draw choice given state
        if(zind[t]==1) { #State 1 - exploration
          emprob=softmax(lambda_explore*W_Average)
        }else if (zind[t]==2) { #State 2 - exploitation;
          emprob=softmax(lambda_exploit*W_Average);
        }else{ # State 3 - inertia;
          emprob=rep(0.000025, N_arms);
          emprob[y[t-1]]=0.99995
        }
        
        ysim=sample(1:N_arms, size = 1, prob = emprob)
        Xmean=mean(c(prior, X[1:(t-1)]))
        gl[t]=ifelse(X[t]>Xmean,0, 1);
        
        ypred=c(ypred, ysim)
        emprobs[t, ]=emprob;
        # for mse 
        pred_prob_ychosen=c(pred_prob_ychosen, emprob[y[t]])
      }

      zind_pred=c(zind_pred, zind)
      y_oos_pred=c(y_oos_pred, ypred)
      All_pred_probs_ychosen=c(All_pred_probs_ychosen, pred_prob_ychosen)
  }
 
  Ypred_iter[, iter]= y_oos_pred
  Pred_prob_iter[, iter]= All_pred_probs_ychosen
  Zpred_iter[, iter]=zind_pred
  
    hr_vec=ifelse(y_oos_pred==pred_data$picks, 1, 0)
    hr_iter[iter]=sum(hr_vec)/nrow(pred_data)
    mse_iter[iter]=mean((1-All_pred_probs_ychosen)^2)
  }

  Ypred_iter=as_tibble(Ypred_iter)
  colnames(Ypred_iter)=paste0("ypred_it", 1:Niter)

  pred_data_with_oos = pred_data_with_oos %>% 
    bind_cols(Ypred_iter) 
  return(list(hr_iter, mse_iter, Zpred_iter, pred_data_with_oos))
}

##** EEI/EWA discounted EV ----
## set r in the estimation code;
#*** Temporal forecasting ----
# K-from, H - ind, K - to, D - number of covariates
out_of_sample_discountEV <- function(oos_t, stfit, dataset, r){
  alpha_tk <- rstan::extract(stfit, pars = 'alpha_tk')[[1]]
  zstar_drawE = apply(alpha_tk, c(1, 2), which.is.max)
  
  beta_draw <- as.matrix(stfit, pars = c("beta"))
  lambda_explore_draw <- as.matrix(stfit, pars = c("lambda_explore"))
  lambda_exploit_draw <- as.matrix(stfit, pars = c("lambda_exploit"))
  rho_draw <- as.matrix(stfit, pars = c("rho"))
  phi_draw <- as.matrix(stfit, pars = c("phi"))
  
  X=pull(roundsData, results)
  y=pull(roundsData, picks)
  Niter=length(lambda_explore_draw)
  Zoos_iter=Yoos_iter=Pred_prob_iter=NULL
  
  hr_iter=mse_iter=rep(0, Niter)
  
  for (iter in 1:Niter){
    
    beta_all=array(beta_draw[iter, ], dim=c(K, H, K, D))
    zind_oos=y_oos_pred= pred_probs =NULL
    
    for (h in 1:H){
      
      lambda_explore = lambda_explore_draw[iter]
      lambda_exploit = lambda_exploit_draw[iter, h]
      rho=rho_draw[iter, h]
      phi=phi_draw[iter, h]
      
      ## individual-specific Xs and ys
      Xh=X[((h-1)*Nobs+1):(h*Nobs)]
      yh=y[((h-1)*Nobs+1):(h*Nobs)]
 
      zind=zstar_drawE[iter, oos_t*h] #estimated state at the last est_obs
      
      beta=beta_all[zind, h, , ]
      
      ew=rep(N0, N_arms);
      W_Average=rep(prior, N_arms);
      Xmean=prior; 
      Nr=1; 
      for (t in 2:oos_t) {
        Xmean=(r*Nr*Xmean+Xh[t-1])/(r*Nr+1);
        Nr=r*Nr+1; 
        
        ew1=ew[yh[t-1]];
        ew[yh[t-1]]=rho*ew[yh[t-1]]+1;
        W_Average[yh[t-1]]=(phi*ew1*W_Average[yh[t-1]]+Xh[t-1])/ew[yh[t-1]];
      }
      
      gl=ifelse(Xh[oos_t]>Xmean, 0, 1);
      XD=c(1, gl);
      
      zpred=ypred=emprobs=NULL
      
      for (t in (oos_t+1):Nobs) {
        ## Draw current state using betas given previous state
        zind <- z_draw(beta, XD)
        beta=beta_all[zind, h, , ]
        
        ## upate still based on actual choices
        ew1=ew[yh[t-1]];
        ew[yh[t-1]]=rho*ew[yh[t-1]]+1;
        W_Average[yh[t-1]]=(phi*ew1*W_Average[yh[t-1]]+Xh[t-1])/ew[yh[t-1]];
        
        ## draw choice given state
        if(zind==1) { #State 1 - exploration
          emprob=softmax(lambda_explore*W_Average)
        }else if (zind==2) { #State 2 - exploitation;
          emprob=softmax(lambda_exploit*W_Average);
        }else{ # State 3 - inertia;
          emprob=rep(0.000025, N_arms);
          emprob[yh[t-1]]=0.99995
        }
        
        ysim=sample(1:N_arms, size = 1, prob = emprob)
        
        Xmean=(r*Nr*Xmean+Xh[t-1])/(r*Nr+1);
        Nr=r*Nr+1;
        gl=ifelse(Xh[t]>Xmean,0, 1);
        XD=c(1, gl);
        zpred=c(zpred, zind)
        ypred=c(ypred, ysim)
        emprobs=c(emprobs, emprob[yh[t]])
      }
      
      zind_oos=c(zind_oos, zpred)
      y_oos_pred=c(y_oos_pred, ypred)
      pred_probs=c(pred_probs, emprobs)
    }
    Zoos_iter=rbind(Zoos_iter, zind_oos)
    Yoos_iter=rbind(Yoos_iter, y_oos_pred)
    Pred_prob_iter=rbind(Pred_prob_iter, pred_probs)
    
    hr_vec=ifelse(y_oos_pred==dataset$picks, 1, 0)
    hr_iter[iter]=sum(hr_vec)/nrow(dataset)
    mse_iter[iter]=mean((1-pred_probs)^2)

  }
  return(list(hr_iter, mse_iter, Yoos_iter, Zoos_iter, Pred_prob_iter))
}

##*** Coss-sectional validation ----
out_of_sample_discountEV_across_subjects <- function(stfit, pred_df, est_df, inddifFull, r){

  pred_data=pred_df %>% 
    arrange(usercode, Rounds)
  
  pred_inddif=inddifFull %>% 
    filter(!(user_id %in% est_df$usercode)) %>% 
    arrange(user_id)
  
  if (INDDIFF) {inddifDataset=as.matrix(pred_inddif %>% dplyr::select(-user_id))
  }else{ inddifDataset=as.matrix(pred_inddif %>% dplyr::select(iota)) } 
  
  ## compute parameter estimates over iterations = f(ind psych profile) 
  gamma_draw <- as.matrix(stfit, pars = c("gamma") )
  
  lambda_explore_unt_draw <- as.matrix(stfit, pars = c("lambda_explore_unt"))
  ## order: betaD 11, 12, 21, 22, 31, 32
  betaD_draw <- as.matrix(stfit, pars = c("betaD"))
  Niter=length(lambda_explore_unt_draw)
  pred_data_with_oos=pred_data
  hr_iter=mse_iter=rep(0, Niter)
  Zpred_iter=Pred_prob_iter=Ypred_iter=matrix(, nrow=nrow(pred_data), ncol=Niter)
  
  for (iter in 1:Niter){

    gamma=matrix(gamma_draw[iter, ], ncol=(nvarHMM+nvarWA))
    betaD=betaD_draw[iter, ]
    lambda_explore=inv_logit(lambda_explore_unt_draw[iter, ])
    
    zind_pred=y_oos_pred= NULL
    pred_probs = NULL
    All_pred_probs_ychosen=NULL
    
    for (h in 1:length(unique(pred_data$pred_ID))){
      ## each individual in the prediction data
      delta=t(inddifDataset[h, ]) %*% gamma
      # beta matrix: K - to, D- number of covariates, K-from state
      beta=array( , dim=c(K,D,K) )
      for (k in 1:K)
      {beta[,,k]= matrix(c(delta[((k-1)*(K-1)+1):(k*(K-1))], 0, betaD[((k-1)*(K-1)+1):(k*(K-1))], 0), ncol=D)};

      lambda_exploit_unt=lambda_explore_unt_draw[iter, ]+exp(delta[K*(K-1)+1])
      if(lambda_exploit_unt<(-50)) {lambda_exploit = 0
      } else if (lambda_exploit_unt>(50)) {
        lambda_exploit = 1
      }else{
        lambda_exploit = inv_logit(lambda_exploit_unt)
      }
      
      if(delta[K*(K-1)+2]<(-50)) {rho = 0
      } else if (delta[K*(K-1)+2]>(50)) {
        rho = 1
      }else{
        rho=inv_logit(delta[K*(K-1)+2])
      }
      
      if(delta[K*(K-1)+3]<(-50)) {phi = 0
      } else if (delta[K*(K-1)+3]>(50)) {
        phi = 1  }else{
        phi=inv_logit(delta[K*(K-1)+3])
      }
      
      X=pull(pred_data %>% filter(pred_ID==h), results)
      y=pull(pred_data %>% filter(pred_ID==h), picks)
      
      ## given subjects' actual path (and rewards) up to t,
      ## and the parameters estimated out-of-sample,
      ## how likely are they to choose y?
      Xmean=prior;
      Nr=1;
      zind=gl=vector("numeric", Nobs)
      zind[1]= sample(x = 1:K, size = 1, prob = pi0)
      gl[1]=ifelse(X[1]> Xmean, 0, 1);
      
      ew=rep(N0, N_arms);
      W_Average=rep(prior, N_arms);
      ## draw a choice from p(y|explore)
      emprobs=matrix(, ncol=N_arms, nrow=Nobs)
      emprobs[1, ]=c(0.333333, .333333, 0.333334);
      ypred=sample(1:N_arms, size = 1, prob = emprobs[1, ])
      pred_prob_ychosen=emprobs[1, ypred]
      
      for (t in 2:Nobs) {

        ## Draw state 
        XD=c(1, gl[t-1]);
        zind[t] <- z_draw(beta[,,zind[t-1]], XD)

        ew1=ew[y[t-1]];
        ew[y[t-1]]=rho*ew[y[t-1]]+1;
        W_Average[y[t-1]]=(phi*ew1*W_Average[y[t-1]]+X[t-1])/ew[y[t-1]];
        
        ## draw choice given state
        if(zind[t]==1) { #State 1 - exploration
          emprob=softmax(lambda_explore*W_Average)
        }else if (zind[t]==2) { #State 2 - exploitation;
          emprob=softmax(lambda_exploit*W_Average);
        }else{ # State 3 - inertia;
          emprob=rep(0.000025, N_arms);
          emprob[y[t-1]]=0.99995
        }
        
        ysim=sample(1:N_arms, size = 1, prob = emprob)
        
        Xmean=(r*Nr*Xmean+X[t-1])/(r*Nr+1);
        Nr=r*Nr+1;
        gl[t]=ifelse(X[t]>Xmean,0, 1);
        
        ypred=c(ypred, ysim)
        emprobs[t, ]=emprob;
        # for mse 
        pred_prob_ychosen=c(pred_prob_ychosen, emprob[y[t]])
      }
  
      zind_pred=c(zind_pred, zind)
      y_oos_pred=c(y_oos_pred, ypred)
      
      All_pred_probs_ychosen=c(All_pred_probs_ychosen, pred_prob_ychosen)
    }
    
    Zpred_iter[, iter]= zind_pred
    Ypred_iter[, iter]= y_oos_pred
    Pred_prob_iter[, iter]= All_pred_probs_ychosen
    
    hr_vec=ifelse(y_oos_pred==pred_data$picks, 1, 0)
    hr_iter[iter]=sum(hr_vec)/nrow(pred_df)
    mse_iter[iter]=mean((1-All_pred_probs_ychosen)^2)
  }
  
  Ypred_iter=as_tibble(Ypred_iter)
  colnames(Ypred_iter)=paste0("ypred_it", 1:Niter)

  pred_data_with_oos = pred_data %>% 
    bind_cols(Ypred_iter) 

  return(list(hr_iter, mse_iter, Zpred_iter, pred_data_with_oos))
}

# PP Checks ----
#* functions ----
y_prob_rep <-function(dataset, stfit){
  ## filtered state probabilities
  alpha_tk <- rstan::extract(stfit, pars = 'alpha_tk')[[1]]
  ## state draws
  empb_g <- rstan::extract(stfit, pars = 'empb_n')[[1]]
  N=nrow(dataset)
  Niter=length(alpha_tk[,1,1])
  J=length(unique(dataset$picks))
  yrep=matrix(, nrow=Niter, ncol=N) #pb_rep=
  for (iter in 1:Niter){
    # prob=NULL
    for (n in 1:N){
      z_draw = sample(x = 1:K, size = 1, prob=alpha_tk[iter, n, ])
      pb=empb_g[iter, n, z_draw, ]
      yrep[iter, n]=sample(1:J, 1, pb, replace = T)
    }
  }
  rm(alpha_tk)
  rm(empb_g)
  return(list(yrep))
}  

#* PPC percentage switching for models that include EEI ----
lag_yrep=function(x) lag(x, 1, 0)

ppc_switch_Sdecile <- function(dataset, stfit, MODEL){
  pp_checks=y_prob_rep(dataset, stfit)
  yrep=as_tibble(t(pp_checks[[1]]))
  Niter=ncol(yrep)
  colnames(yrep)=paste0("yrep_", 1:Niter)
  
  lag_yrep=yrep %>% mutate_all(lag_yrep)
  switch_yrep=ifelse(yrep==lag_yrep, 0, 1)
  colnames(switch_yrep)=paste0("yrep", 1:Niter)
  
  switch_obs_yrep=dataset %>% 
    group_by(userid) %>% 
    mutate(lag_picks=lag(picks, 1, 0)) %>% 
    mutate(obs_switches=ifelse(picks==lag_picks, 0, 1)) %>% 
    ungroup() %>% 
    dplyr::select(userid, Rounds, obs_switches) %>% 
    cbind(switch_yrep) %>% 
    filter(Rounds!=1) %>% 
    group_by(userid) %>% 
    summarise_at(vars(obs_switches:paste0("yrep", Niter)), mean) %>% 
    pivot_longer(-c(userid, obs_switches), names_to="iter", values_to = "ppc_switch") %>% 
    mutate(Model=MODEL)
  return(switch_obs_yrep)
}


##* PPC percentage switching for EWA model ----
ppc_switch_ewa_Sdecile <- function(dataset, stfit, MODEL){
  yrep=data.frame(t(as.matrix(stfit, pars=c("y_rep"))))
  Niter=ncol(yrep)
  colnames(yrep)=paste0("yrep_", 1:Niter)
  
  lag_yrep=yrep %>% mutate_all(lag_yrep)
  switch_yrep=ifelse(yrep==lag_yrep, 0, 1)
  colnames(switch_yrep)=paste0("yrep", 1:Niter)
  
  switch_obs_yrep=dataset %>% 
    group_by(userid) %>% 
    mutate(lag_picks=lag(picks, 1, 0)) %>% 
    mutate(obs_switches=ifelse(picks==lag_picks, 0, 1)) %>% 
    ungroup() %>% 
    dplyr::select(userid, Rounds, obs_switches) %>% 
    cbind(switch_yrep) %>% 
    filter(Rounds!=1) %>% 
    group_by(userid) %>%
    summarise_at(vars(obs_switches:paste0("yrep", Niter)), mean) %>% 
    pivot_longer(-c(userid, obs_switches), names_to="iter", values_to = "ppc_switch") %>% 
    mutate(Model=MODEL)
  return(switch_obs_yrep)
}

## Report parameter estimates for EEI/EWA model ----
pars = c("gamma[1,1]", "gamma[1,2]", "gamma[1,3]", "gamma[1,4]", "gamma[1,5]", 
  "gamma[1,6]",  "betaD", "lambda_explore", "lambda_explore_unt", "gamma[1,7]", "gamma[1,8]", "gamma[1,9]")

Report_par_est <- function(stfit){
  parMeans  = round(summary(stfit, pars = pars, 
                            probs=c(0.025, 0.975))$summary[,c(1)], 3)
  parMeans[15]=round(inv_logit(parMeans[14]+exp(parMeans[15])), 3)
  parMeans[16:17]=round(inv_logit(parMeans[16:17]), 3)
  Means_df=parMeans[-14]
  
  parCI  = round(summary(stfit, pars = pars, 
                         probs=c(0.025, 0.975))$summary[,c(4, 5)], 3)
  
  parCI[15,]=round(inv_logit(parCI[14,]+exp(parCI[15,])), 3)
  parCI[16:17,]=round(inv_logit(parCI[16:17,]), 3)
  
  colnames(parCI)<-c( "V1", "V2")
  CI_df=as.data.frame(parCI) %>% unite("V1", "V1", "V2", sep=", ") %>% 
    mutate(last_bracket=rep("]", n()), 
           first_bracket=rep("[", n())) %>% 
    unite("CI", c(first_bracket, as.character("V1"), last_bracket), sep="") 
  CI_df=CI_df[-14,]
  
  Pars_df=NULL
  for (i in 1:length(Means_df) )
    Pars_df=rbind(Pars_df, rbind(Means_df[i], CI_df[i] ))
  
  return(Pars_df)
}
