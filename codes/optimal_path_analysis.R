## Gittins calculation using the BAYESIAN APPROACH
rm(list=ls())
library(tidyverse)
library(magrittr)
library(nnet)
library(ggpubr)
library(Hmisc)
library(stargazer)

## Source functions ----
PATH_FUNCTION= "/set/local/path/here" 
PATH_DATA="/set/local/path/here"
PATH_RESULTS="/set/local/path/here"
PATH_PPC='set/your/path/here'
PATH_PLOTS='set/your/path/here'

## Source functions ----
source(paste(PATH_FUNCTION,"/EEtradeoffs_functions.R", sep="") ) 

## Import the five sets of experimental draws ----
exp_draws=read_csv(paste0(PATH_DATA, "/exp_draws_study1.csv"))

set.seed(1234567890)
## overall number of trials - time horizon for optimization
Nobs=100
N_arms=3
## true means (unknown) - a Wiener process with normal priors N(mean(mean_reward), sigma_w), where sigma_w is known
mean_reward=c(65,50, 35)
sigma_w=15

## Exact vs. approximate Gittins index for Figure WA1 ----
## Bayesian updating 
## process and prior precisions and prior mean
precision_n=sample_mean_bayesian=matrix(rep(0, Nobs*N_arms), ncol=N_arms)
beta_0=1/(sigma_w^2)
beta_r=1/(sigma_w^2)
## prior is 50
theta_0=50
## use set 1 as an example
uncertain_reward=as.matrix(exp_draws %>% 
                             filter(Set=="set1") %>% 
                             select(A, B, C))

##  updating loop - assume known variance
beta_n=beta_0
theta_n=theta_0
sample_mean_bayesian[1, ]=rep(theta_0, N_arms)
precision_n[1, ]=rep(beta_0, N_arms)
for (i in 2:Nobs)
{   
  theta_n=(beta_n*theta_n+beta_r*uncertain_reward[(i-1),])/(beta_n+beta_r) 
  beta_n=beta_n+beta_r
  precision_n[i,]=beta_n
  sample_mean_bayesian[i, ]=theta_n
}

##* Exact GI - Gittins and Jones (2011)----
## exact value for unknown mean and known variance
nu=read.table(paste0(PATH_DATA, "/nu.txt"), header=T)

nu_exact=c(nu[1:10,3], 
           rep(nu[11,3], 10),
           rep(nu[12,3], 10),
           rep(nu[13,3], 10),
           rep(nu[14,3], 10),
           rep(nu[15,3], 10), 
           rep(nu[16,3], 10), 
           rep(nu[17,3], 10), 
           rep(nu[18,3], 10), 
           rep(nu[19,3], 10))
## compute exact nu
GI_exact=sample_mean_bayesian+sigma_w*nu_exact

## Optimal choice calculation using exact GI
optimal_choice=rbind(diag(3),matrix(rep(0, N_arms*(Nobs-3)), ncol=N_arms))
GI_chosen=c(diag(GI_exact[1:3,]),rep(0,(Nobs-3)))
picks=c(1:3,rep(0,(Nobs-3)))
for (i in 4:Nobs)
{
  a=rep(0, 3)
  for (j in 1:N_arms)
  {
    a[j]=GI_exact[length(optimal_choice[1:i,j][optimal_choice[1:i,j]==1]),j]
  }
  
  picks[i]=which.max(a)
  optimal_choice[i,which.max(a)]=1
  GI_chosen[i]=GI_exact[length(optimal_choice[1:i,which.max(a)][optimal_choice[1:i,which.max(a)]==1]),which.max(a)]
}

colnames(GI_exact)=c("GI1", "GI2", "GI3")
GI_exact = data.frame(GI_exact)%>% 
  mutate(Round=1:100) %>% 
  gather(Arm, GI_value, -Round)

##* Approximate GI - BREZZI AND LAI(2002) ----
## UPPER AND LOWER CONFIDENCE BOUNDS - YAO (2006)
## discrete time discount rate
beta=0.99
## continuous time discount rate
c=-log(beta)

UB=LB=GI_B=rep(0,Nobs)
for (i in 1:Nobs)
{     s=1/(i*c)
UB[i]=(1/sqrt(i))*(sqrt(s/2))-(0.583/i)/(sqrt(1+1/i))
LB[i]=(1/sqrt(i))*Phi(s)-(0.583/i)/(sqrt(1+1/i))
GI_B[i]=(UB[i]+LB[i])/2
}

## computation of approximate gittins for our application
GI_BLY_bayesian=sample_mean_bayesian+sigma_w*GI_B

##** Plot WA1 - Exact vs. Approximate Gittins ----
Approx_data=data.frame(Round=1:100, Index.value=nu_exact, Type=rep("Exact", Nobs)) %>% 
  bind_rows(data.frame(Round=1:100, Index.value=GI_B, Type=rep("Approx", Nobs)))

Approx_data %>% ggplot(aes(x=Round, y=Index.value, linetype=Type)) +
  geom_line(size=.5)+
  scale_linetype_manual(values = c(1,2))+
  scale_y_continuous(name="Index value")+
  theme_light()+theme(legend.position="bottom")

plot_scale <- 4
plot_aspect <- 1.5
save_plot <- purrr::partial(ggsave, width = plot_aspect * plot_scale, height = 1 * plot_scale)
save_plot(paste0(PATH_PLOTS, 'comp_approx_exact.pdf')  )

## Optimal path analysis for Study 1 ----
##* Approximate Gittins for our experimetal draws ----
exp_draws=exp_draws %>% group_by(Set) %>% 
  mutate(groupID=cur_group_id()) %>% 
  ungroup()

X=as.matrix(exp_draws[,2:4])
Round=pull(exp_draws, Round)

## overall number of trials - time horizon for optimization
H=length(unique(exp_draws$Set))
N=Nobs*H
n_sets=length(unique(exp_draws$Set))

## true means (unknown) - a Wiener process with normal priors N(mean(mean_reward), sigma_w), where sigma_w is known
uncertain_reward=c(65,50,35)
sigma_w=15
sigma_w_sq=sigma_w^2

set.seed(1234567890)
optimal_choice=optimal_picks=BLY_full=Value_exploration_full=Posterior_mean_full=NULL
Index_BLY=c()
theta_0=rep(50,N_arms)
bly_prior=theta_0+sigma_w*GI_B[1]

for (i in 1:N)
  {  
  ## reset at the prior
  if(Round[i]==1) {
      theta_n=rep(50,N_arms)
      sigma_sqn=sigma_0sqn=rep(sigma_w^2, N_arms)
      sigma_w_sq=sigma_w^2
      Index_BLY=bly_prior
      optimal_choice=NULL 
  }
  set.seed(1234567890)
  picks=which.is.max(Index_BLY)
  
  optimal_choice=c(optimal_choice, picks)
  
    theta_n[picks]=((1/sigma_sqn[picks])*theta_n[picks]+(1/sigma_w_sq)*X[i,picks])/((1/sigma_sqn[picks])+(1/sigma_w_sq)) 
    sigma_sqn[picks]=sigma_sqn[picks]/(1+(sigma_sqn[picks]/sigma_w_sq))
    
    Index_BLY[picks]=theta_n[picks]+sigma_w*GI_B[length(optimal_choice[optimal_choice==picks])+1]
    Value_exploration=Index_BLY-theta_n
    
    BLY_full=rbind(BLY_full, Index_BLY)
    Posterior_mean_full=rbind(Posterior_mean_full, theta_n)
    Value_exploration_full=rbind(Value_exploration_full, Value_exploration)
    if (Round[i]==100) optimal_picks=c(optimal_picks, optimal_choice)
}

Indexdata=data.frame(optimal_picks=optimal_picks, BLY_A=BLY_full[,1],BLY_B=BLY_full[,2], BLY_C=BLY_full[,3], 
                     Pmean_A=Posterior_mean_full[,1], Pmean_B=Posterior_mean_full[,2], Pmean_C=Posterior_mean_full[,3],
                     Vexplore_A=Value_exploration_full[,1], Vexplore_B=Value_exploration_full[,2], Vexplore_C=Value_exploration_full[,3])

exp_draws_with_optimal=exp_draws %>% bind_cols(Indexdata)
exp_draws_with_optimal %<>% mutate(optimal_results=case_when(optimal_picks==1 ~ A,
                                       optimal_picks==2 ~ B,
                                       TRUE ~ C))
exp_draws_with_optimal=exp_draws_with_optimal %>% mutate(DR=rep(.99, n()))

## average rewards
exp_draws_with_optimal %>% group_by(Set) %>% summarise(sum(optimal_results))
temp=exp_draws_with_optimal %>% filter(optimal_picks!=1) %>% 
  group_by(Set) %>% 
  summarise(n())


### BLY plot
BLYI=exp_draws_with_optimal %>% 
  filter(Set=="set4") %>% 
  dplyr::select(Round, Set, BLY_A, BLY_B, BLY_C) %>% 
  pivot_longer(-c(Round, Set), names_to="Arm", values_to="Index_value") %>% 
  mutate(Measure=rep("Gittins index", n())) %>% 
  bind_rows(exp_draws_with_optimal %>%
              filter(Set=="set4") %>% 
              dplyr::select(Round,Set,Pmean_A, Pmean_B, Pmean_C) %>% 
              pivot_longer(-c(Round, Set), names_to="Arm", values_to="Index_value")%>%
              mutate(Measure=rep("Posterior mean", n()))) %>% 
  bind_rows(exp_draws_with_optimal %>%
              filter(Set=="set4") %>% 
              dplyr::select(Round,Set,Vexplore_A,Vexplore_B, Vexplore_C ) %>% 
              pivot_longer(-c(Round, Set), names_to="Arm", values_to="Index_value")%>%
              mutate(Measure=rep("Value of exploration", n()))) %>% 
  mutate(Arm=case_when(grepl("A", Arm)~1,
                       grepl("C", Arm)~3,
                       TRUE~2))
  
##** Figure 6  ----
BLYI %>%  ggplot(aes(x=as.numeric(Round), y=as.numeric(Index_value), linetype=as.factor(Arm)))+
  geom_line()+scale_y_continuous(name="Value")+
  scale_linetype_manual(values= 1:3,
                     labels=c("1", "2", "3"))+
  labs(x="Round", linetype="Arms")+
  theme_light()+theme(legend.position="bottom")+
  facet_wrap(.~ Measure, ncol=3)

plot_scale <- 3
plot_aspect <- 2.5
save_plot <- purrr::partial(ggsave, width = plot_aspect * plot_scale, height = 1 * plot_scale)
save_plot(paste0(PATH_PLOTS, '/optimalPathBLYI.pdf')  )

##** Actual vs. optimal behavior for Study 1 ----
roundsData=read_csv(paste0(PATH_DATA, "/businessTask_Study1.csv"))
roundsData %<>% mutate(Rounds=rounds+1) %>% dplyr::select(-rounds)
roundsData%<>% group_by(userid) %>% 
  mutate(ID = cur_group_id()) %>% 
  ungroup()

roundsData_with_optimal = roundsData %>% 
  mutate(random_picks=sample(1:3, n(), replace = T)) %>% 
  left_join(exp_draws_with_optimal %>% 
              dplyr::select(Set, Round, A, B, C, optimal_picks, optimal_results), 
            by=c("Set"="Set", "Rounds"="Round")) %>% 
  mutate(random_rewards=case_when(random_picks==1~ A,
                                  random_picks==2 ~B,
                                  TRUE~C))

prSO_actual=roundsData_with_optimal %>%
  filter(picks!=1) %>% 
  group_by(userid) %>% 
  summarise(prSO_actual=n()/Nobs)
mean(prSO_actual$prSO_actual)
sd(prSO_actual$prSO_actual)/sqrt(length(unique(roundsData$userid)))

prSO_optimal=roundsData_with_optimal %>%
  filter(optimal_picks!=1) %>% 
  group_by(userid) %>% 
  summarise(prSO_optimal=n()/Nobs)
mean(prSO_optimal$prSO_optimal)
sd(prSO_optimal$prSO_optimal)/sqrt(length(unique(roundsData$userid)))

totalRewards=roundsData_with_optimal %>% 
  group_by(userid) %>% 
  summarise(Random=sum(random_rewards), Experimental=sum(results), 
            Optimal=sum(optimal_results), 
            Perfect_info=sum(A)) 

totalRewards=totalRewards %>% 
  pivot_longer(-userid, names_to="Condition", values_to="Total_rewards")

##** Overall optimal vs. actual rewards ----
totalRewards$Condition=factor(totalRewards$Condition, 
                              levels = c("Random", "Experimental", "Optimal", "Perfect_info"))
### means and se, optimal vs. actual rewards per group 
## Table 1- Benchmark comparisons
totalRewards %>% group_by(Condition) %>% 
  summarise(meanTR=mean(Total_rewards), sdTR=sd(Total_rewards)) %>% 
  mutate(improvement_random=(meanTR-meanTR[1])/(meanTR[1]),
         efficiency_PI=(meanTR-meanTR[1])/(meanTR[4]-meanTR[1]),
         efficiency_Optimal=(meanTR-meanTR[1])/(meanTR[3]-meanTR[1]))

#### Plot overall rewards - Figure 7
Rewards_boxplot=totalRewards %>%
  ggplot(aes(x = as.factor(Condition), y =Total_rewards, group=Condition))+
  geom_boxplot() +
  stat_summary(aes(color=as.factor(Condition)), fun.data = mean_cl_boot,position=position_nudge(x = 0, y = 0))+
  scale_x_discrete(labels= c("Randon", "Experimental", "Optimal", "Perfect info")) +
  scale_color_manual(values= c("grey", "grey", "grey", "grey")) +
  labs(x = " ", y = "Overall rewards", color="Condition")+
  theme_light()+theme(legend.position=" none ")+
  theme(axis.text.x = element_text(angle = 15))

Rewards_boxplot

plot_scale <- 4
plot_aspect <- 1.5
save_plot <- purrr::partial(ggsave, width = plot_aspect * plot_scale, height = 1 * plot_scale)
save_plot(paste0(PATH_PLOTS,'/total_rewards.pdf')) 

### Optimal path analysis for Study 2 - Two business simulations ----
##* Optimal path for the two business sims ----
exp_draws_with_optimal_study2=exp_draws_with_optimal %>% 
  filter(Set %in% c("set2", "set4")) %>% 
  mutate(Business_sim=case_when(Set=="set2" ~ "business_sim_1",
                                TRUE~"business_sim_2"))
  
##* Optimal vs. actual rewards ----
##** Load data ----
roundsData_2sims=read_csv(paste(PATH_DATA, "/roundsData_xtreme2.csv",  sep=""))  

roundsData_2sims %<>% 
  ## for this usercode, we didn't have any data from the website
  filter(usercode!="2RM6E4RVD") %>% 
  arrange(usercode, Business_sim, Rounds)%>% 
  #mutate(ID = group_indices(., usercode))
  group_by(usercode) %>%
  mutate(ID = cur_group_id()) %>%
  ungroup()

##** Descriptives ----
## user level tot rewards, for comparison with optimal path
userlevel_tot_rewards=roundsData_2sims %>% 
  group_by(usercode, Business_sim) %>% 
  summarise(tot_rewards=sum(results)) %>% 
  group_by(Business_sim) %>% 
  summarise(meanTR=mean(tot_rewards))

set.seed(1234567890)
roundsData_with_optimal_xtreme2 = roundsData_2sims %>% 
  left_join(exp_draws_with_optimal_study2 %>% 
              dplyr::select(Business_sim, Round, A, B, C, optimal_picks, optimal_results), 
            by=c("Business_sim"="Business_sim", "Rounds"="Round")) %>% 
  mutate(random_picks=sample(1:3, n(), replace = T)) %>% 
  mutate(random_rewards=case_when(random_picks==1 ~ A,
                                  random_picks==2 ~ B,
                                  TRUE~C))

totalRewards_xtreme2=roundsData_with_optimal_xtreme2 %>% 
  group_by(ID, Business_sim) %>% 
  summarise(Random=sum(random_rewards), Experimental=sum(results), 
            Optimal=sum(optimal_results), 
            Perfect_info=sum(A))

totalRewards_xtreme2=totalRewards_xtreme2 %>%   
  pivot_longer(-c(ID, Business_sim), names_to="Condition", values_to="Total_rewards")

### Overall optimal vs. actual rewards
totalRewards_xtreme2$Condition=factor(totalRewards_xtreme2$Condition, 
                                      levels = c("Random", "Experimental", "Optimal", "Perfect_info"))

### means and se, optimal vs. actual rewards per group 
## table benchmark comparisons
TR_summary=totalRewards_xtreme2 %>% filter(Business_sim=="business_sim_1") %>% 
  group_by(Condition) %>% 
  summarise(meanTR=mean(Total_rewards), sdTR=sd(Total_rewards)) %>% 
  mutate(improvement_random=(meanTR-meanTR[1])/(meanTR[1]),
         efficiency_PI=(meanTR-meanTR[1])/(meanTR[4]-meanTR[1]),
         efficiency_Optimal=(meanTR-meanTR[1])/(meanTR[3]-meanTR[1]))

TR_user_summary=totalRewards_xtreme2 %>% 
  filter(Condition!="Perfect_info") %>% 
  pivot_wider(names_from = Condition, values_from = c(Total_rewards))%>% 
  mutate(efficiency_PI=(Experimental - Random)/(Optimal-Random))

TR_user_summary %>% group_by(Business_sim) %>% 
  summarise(mean(efficiency_PI))

t.test(efficiency_PI~Business_sim, paired=T, data=TR_user_summary)

## pr low performing arms sampled
Nobs=100
prLPO_actual=roundsData_with_optimal_xtreme2 %>%
  filter(picks!=1) %>% 
  group_by(ID, Business_sim) %>% 
  summarise(prLPO=n()/Nobs)
prLPO_actual %>% 
  group_by(Business_sim) %>% 
  summarise(mean(prLPO))

prLPO_optimal=roundsData_with_optimal_xtreme2 %>%
  filter(optimal_picks!=1) %>% 
  group_by(ID, Business_sim) %>% 
  summarise(prLPO=n()/Nobs)
prLPO_optimal %>% 
  group_by(Business_sim) %>% 
  summarise(mean(prLPO))

t.test(prLPO~Business_sim, paired=T, data=prLPO_actual)

### Optimal path analysis for Study 3 - Time horison ----
##* Discount rate =.995, for R = 200 ----
exp_draws_study3=read_csv(paste0(PATH_DATA, "/exp_draws_study3.csv") )

## overall number of trials - time horizon for optimization
Nobs=200
beta=0.995
## continuous time discount rate
cc=-log(beta)
UB=LB=GI_B=rep(0,Nobs)
for (i in 1:Nobs)
{     s=1/(i*cc)
UB[i]=(1/sqrt(i))*(sqrt(s/2))-(0.583/i)/(sqrt(1+1/i))
LB[i]=(1/sqrt(i))*Phi(s)-(0.583/i)/(sqrt(1+1/i))
GI_B[i]=(UB[i]+LB[i])/2
}

X=as.matrix(exp_draws_study3 %>% filter(Set=="R200") %>% 
            dplyr::select(A, B, C))
Round=1:200
## true means (unknown) - a Wiener process with normal priors N(mean(mean_reward), sigma_w), where sigma_w is known
uncertain_reward=c(65,50,35)
sigma_w=15
sigma_w_sq=sigma_w^2

## Optimal path computation - retrieve picks
set.seed(1234567890)
optimal_choice=optimal_picks=BLY_full=NULL
Index_BLY=c()
theta_0=rep(50,N_arms) # prior
bly_prior=theta_0+sigma_w*GI_B[1]

for (i in 1:Nobs)
{  
  ## reset at the prior
  if(Round[i]==1) {
    theta_n=rep(50,N_arms)
    sigma_sqn=sigma_0sqn=rep(sigma_w^2, N_arms)
    sigma_w_sq=sigma_w^2
    Index_BLY=bly_prior
    optimal_choice=NULL 
  }
  set.seed(1234567890)
  picks=which.is.max(Index_BLY)
  
  optimal_choice=c(optimal_choice, picks)
  
  theta_n[picks]=((1/sigma_sqn[picks])*theta_n[picks]+(1/sigma_w_sq)*X[i,picks])/((1/sigma_sqn[picks])+(1/sigma_w_sq)) 
  sigma_sqn[picks]=sigma_sqn[picks]/(1+(sigma_sqn[picks]/sigma_w_sq))
  
  Index_BLY[picks]=theta_n[picks]+sigma_w*GI_B[length(optimal_choice[optimal_choice==picks])+1]
  BLY_full=rbind(BLY_full, Index_BLY)
  if (Round[i]==200) optimal_picks=c(optimal_picks, optimal_choice)
}

Indexdata=data.frame(optimal_picks=optimal_picks, BLY_A=BLY_full[,1],BLY_B=BLY_full[,2], BLY_C=BLY_full[,3])
exp_draws_with_optimal_dr995=exp_draws_study3 %>% filter(Set=="R200") %>% bind_cols(Indexdata)
exp_draws_with_optimal_dr995 %<>%mutate(optimal_results=case_when(optimal_picks==1 ~ A,
                                                            optimal_picks==2 ~ B,
                                                            TRUE ~ C))
exp_draws_with_optimal_dr995%<>%mutate(DR=rep(.995, n()))

#* Discount rate =.99, for R100----
## overall number of trials - time horizon for optimization
Nobs=100
beta=0.99
## continuous time discount rate
cc=-log(beta)
UB=LB=GI_B=rep(0,Nobs)
for (i in 1:Nobs)
{     s=1/(i*cc)
UB[i]=(1/sqrt(i))*(sqrt(s/2))-(0.583/i)/(sqrt(1+1/i))
LB[i]=(1/sqrt(i))*Phi(s)-(0.583/i)/(sqrt(1+1/i))
GI_B[i]=(UB[i]+LB[i])/2
}

X=as.matrix(exp_draws_study3 %>% filter(Set=="R100") %>% 
              dplyr::select(A, B , C))
head(X)
Round=1:100
N_arms=3

## true means (unknown) - a Wiener process with normal priors N(mean(mean_reward), sigma_w), where sigma_w is known
uncertain_reward=c(65,50,35)
sigma_w=15
sigma_w_sq=sigma_w^2
## retreive optimal picks
set.seed(1234567890)
optimal_choice=optimal_picks=BLY_full=NULL
Index_BLY=c()
theta_0=rep(50,N_arms) # prior
bly_prior=theta_0+sigma_w*GI_B[1]

for (i in 1:Nobs)
{  
  ## reset at the prior
  if(Round[i]==1) {
    theta_n=rep(50,N_arms)
    sigma_sqn=sigma_0sqn=rep(sigma_w^2, N_arms)
    sigma_w_sq=sigma_w^2
    Index_BLY=bly_prior
    optimal_choice=NULL 
  }
  set.seed(1234567890)
  picks=which.is.max(Index_BLY)
  
  optimal_choice=c(optimal_choice, picks)
  
  theta_n[picks]=((1/sigma_sqn[picks])*theta_n[picks]+(1/sigma_w_sq)*X[i,picks])/((1/sigma_sqn[picks])+(1/sigma_w_sq)) 
  sigma_sqn[picks]=sigma_sqn[picks]/(1+(sigma_sqn[picks]/sigma_w_sq))
  
  Index_BLY[picks]=theta_n[picks]+sigma_w*GI_B[length(optimal_choice[optimal_choice==picks])+1]
  BLY_full=rbind(BLY_full, Index_BLY)
  if (Round[i]==100) optimal_picks=c(optimal_picks, optimal_choice)
}

Indexdata=data.frame(optimal_picks=optimal_picks, BLY_A=BLY_full[,1],BLY_B=BLY_full[,2], BLY_C=BLY_full[,3])
exp_draws_with_optimal_dr99=exp_draws_study3 %>% filter(Set=="R100") %>% 
  bind_cols(Indexdata)
exp_draws_with_optimal_dr99 %<>%mutate(optimal_results=case_when(optimal_picks==1 ~ A,
                                                                 optimal_picks==2 ~ B,
                                                                 TRUE ~ C))
exp_draws_with_optimal_dr99%<>%mutate(DR=rep(.99, n()))

#* Discount rate =.98, for R50----
## overall number of trials - time horizon for optimization
Nobs=50
beta=0.98
## continuous time discount rate
cc=-log(beta)
UB=LB=GI_B=rep(0,Nobs)
for (i in 1:Nobs)
{     s=1/(i*cc)
UB[i]=(1/sqrt(i))*(sqrt(s/2))-(0.583/i)/(sqrt(1+1/i))
LB[i]=(1/sqrt(i))*Phi(s)-(0.583/i)/(sqrt(1+1/i))
GI_B[i]=(UB[i]+LB[i])/2
}

X=as.matrix(exp_draws_study3 %>% filter(Set=="R50") %>% 
              dplyr::select(A, B , C))
Round=1:50
N_arms=3
## true means (unknown) - a Wiener process with normal priors N(mean(mean_reward), sigma_w), where sigma_w is known
uncertain_reward=c(65,50,35)
sigma_w=15
sigma_w_sq=sigma_w^2
## retrieve picks
set.seed(1234567890)
optimal_choice=optimal_picks=BLY_full=NULL
Index_BLY=c()
theta_0=rep(50,N_arms) # prior
bly_prior=theta_0+sigma_w*GI_B[1]

for (i in 1:Nobs)
{  
  ## reset at the prior
  if(Round[i]==1) {
    theta_n=rep(50,N_arms)
    sigma_sqn=sigma_0sqn=rep(sigma_w^2, N_arms)
    sigma_w_sq=sigma_w^2
    Index_BLY=bly_prior
    optimal_choice=NULL 
  }
  set.seed(1234567890)
  picks=which.is.max(Index_BLY)
  
  optimal_choice=c(optimal_choice, picks)
  
  theta_n[picks]=((1/sigma_sqn[picks])*theta_n[picks]+(1/sigma_w_sq)*X[i,picks])/((1/sigma_sqn[picks])+(1/sigma_w_sq)) 
  sigma_sqn[picks]=sigma_sqn[picks]/(1+(sigma_sqn[picks]/sigma_w_sq))
  
  Index_BLY[picks]=theta_n[picks]+sigma_w*GI_B[length(optimal_choice[optimal_choice==picks])+1]
  BLY_full=rbind(BLY_full, Index_BLY)
  if (Round[i]==50) optimal_picks=c(optimal_picks, optimal_choice)
}

Indexdata=data.frame(optimal_picks=optimal_picks, BLY_A=BLY_full[,1],BLY_B=BLY_full[,2], BLY_C=BLY_full[,3])
exp_draws_with_optimal_dr98=exp_draws_study3 %>% filter(Set=="R50") %>% 
  bind_cols(Indexdata)

exp_draws_with_optimal_dr98 %<>%mutate(optimal_results=case_when(optimal_picks==1 ~ A,
                                                                        optimal_picks==2 ~ B,                                                                     
                                                                 TRUE ~ C))
exp_draws_with_optimal_dr98%<>%mutate(DR=rep(.98, n()))

#* Discount rate =.98, for R20----
## overall number of trials - time horizon for optimization
Nobs=20
beta=0.95
## continuous time discount rate
cc=-log(beta)
UB=LB=GI_B=rep(0,Nobs)
for (i in 1:Nobs)
{     s=1/(i*cc)
UB[i]=(1/sqrt(i))*(sqrt(s/2))-(0.583/i)/(sqrt(1+1/i))
LB[i]=(1/sqrt(i))*Phi(s)-(0.583/i)/(sqrt(1+1/i))
GI_B[i]=(UB[i]+LB[i])/2
}

X=as.matrix(exp_draws_study3 %>% filter(Set=="R20") %>% 
              dplyr::select(A, B , C))
head(X)
Round=1:20
N_arms=3

## true means (unknown) - a Wiener process with normal priors N(mean(mean_reward), sigma_w), where sigma_w is known
uncertain_reward=c(65,50,35)
sigma_w=15
sigma_w_sq=sigma_w^2
## retreive optimal picks
set.seed(1234567890)
optimal_choice=optimal_picks=BLY_full=NULL
Index_BLY=c()
theta_0=rep(50,N_arms) # prior
bly_prior=theta_0+sigma_w*GI_B[1]

for (i in 1:Nobs)
{  
  ## reset at the prior
  if(Round[i]==1) {
    theta_n=rep(50,N_arms)
    sigma_sqn=sigma_0sqn=rep(sigma_w^2, N_arms)
    sigma_w_sq=sigma_w^2
    Index_BLY=bly_prior
    optimal_choice=NULL 
  }
  set.seed(1234567890)
  picks=which.is.max(Index_BLY)
  
  optimal_choice=c(optimal_choice, picks)
  
  theta_n[picks]=((1/sigma_sqn[picks])*theta_n[picks]+(1/sigma_w_sq)*X[i,picks])/((1/sigma_sqn[picks])+(1/sigma_w_sq)) 
  sigma_sqn[picks]=sigma_sqn[picks]/(1+(sigma_sqn[picks]/sigma_w_sq))
  
  Index_BLY[picks]=theta_n[picks]+sigma_w*GI_B[length(optimal_choice[optimal_choice==picks])+1]
  BLY_full=rbind(BLY_full, Index_BLY)
  if (Round[i]==20) optimal_picks=c(optimal_picks, optimal_choice)
}

Indexdata=data.frame(optimal_picks=optimal_picks, BLY_A=BLY_full[,1],BLY_B=BLY_full[,2], BLY_C=BLY_full[,3])
exp_draws_with_optimal_dr95=exp_draws_study3 %>% filter(Set=="R20") %>% 
  bind_cols(Indexdata)
exp_draws_with_optimal_dr95 %<>%mutate(optimal_results=case_when(optimal_picks==1 ~ A,
                                                                 optimal_picks==2 ~ B,
                                                                 TRUE ~ C))
exp_draws_with_optimal_dr95%<>%mutate(DR=rep(.95, n()))

## apend optimal data
exp_draws_with_optimal_4conditions=exp_draws_with_optimal_dr995 %>% 
  bind_rows(exp_draws_with_optimal_dr99) %>% 
  bind_rows(exp_draws_with_optimal_dr98) %>% 
  bind_rows(exp_draws_with_optimal_dr95) 

##* Optimal path vs. actual behavior ----
##** Load data ----
roundsData_xtreme3=read_csv(paste(PATH_DATA, "/roundsData_xtreme3.csv",  sep=""))  
psychVars=read_csv(paste(PATH_DATA, "/psychVars_xtreme3.csv",  sep=""))

roundsData_xtreme3 %<>% 
  mutate(usercode=gsub("X", "", usercode) )
psychVars %<>% 
  mutate(usercode=gsub("X", "", usercode) )
roundsData_xtreme3 %<>% arrange(usercode, Rounds) 
psychVars %<>% arrange(usercode)

roundsData_xtreme3=roundsData_xtreme3 %>% 
  filter(usercode %in% psychVars$usercode)

psychVars=psychVars %>% 
  filter(usercode %in% roundsData_xtreme3$usercode)

roundsData = roundsData_xtreme3 %>%  
  group_by(usercode) %>% 
  mutate(condition=rep(last(Rounds), n()),
         lastT=ifelse(row_number()==n(), 1,0)) %>% 
  ungroup()

set.seed(1234567890)
roundsData_with_optimal_xtreme3 = roundsData %>% 
  left_join(exp_draws_with_optimal_4conditions %>% 
              mutate(condition=case_when(Set=="R20" ~ 20,
                                         Set=="R50" ~ 50,
                                         Set=="R100" ~ 100,
                                         TRUE ~ 200)) %>% 
              dplyr::select(condition, Round, A, B, C, optimal_picks, optimal_results), 
            by=c("condition"="condition", "Rounds"="Round")) %>% 
  mutate(random_picks=sample(1:3, n(), replace = T)) %>% 
  mutate(random_rewards=case_when(random_picks==1 ~ A,
                                  random_picks==2 ~ B,
                                  TRUE~C))

totalRewards_xtreme3=roundsData_with_optimal_xtreme3 %>% 
  group_by(usercode, condition) %>% 
  summarise(Random=sum(random_rewards), Experimental=sum(results), 
            Optimal=sum(optimal_results), 
            Perfect_info=sum(A))

totalRewards_xtreme3=totalRewards_xtreme3 %>%   
  pivot_longer(-c(usercode, condition), names_to="Rewards_condition", values_to="Total_rewards")

###** Overall optimal vs. actual rewards ----
totalRewards_xtreme3$Condition=factor(totalRewards_xtreme3$Rewards_condition, 
                                      levels = c("Random", "Experimental", "Optimal", "Perfect_info"))

### means and se, optimal vs. actual rewards per group 
## table benchmark comparisons
TR_summary=totalRewards_xtreme3 %>%  
  group_by(Condition) %>% 
  summarise(meanTR=mean(Total_rewards), sdTR=sd(Total_rewards)) %>% 
  mutate(improvement_random=(meanTR-meanTR[1])/(meanTR[1]),
         efficiency_PI=(meanTR-meanTR[1])/(meanTR[4]-meanTR[1]),
         efficiency_Optimal=(meanTR-meanTR[1])/(meanTR[3]-meanTR[1]))

TR_user_summary=totalRewards_xtreme3 %>% 
  dplyr::select(-Condition) %>% 
  filter(Rewards_condition!="Perfect_info") %>% 
  pivot_wider(names_from = Rewards_condition, values_from = c(Total_rewards))%>% 
  mutate(efficiency_PI=(Experimental - Random)/(Optimal-Random))

TR_user_summary %>% group_by(condition) %>% 
  summarise(mean(efficiency_PI))

a=oneway.test(efficiency_PI~as.factor(condition), data=TR_user_summary)
a
a=aov(efficiency_PI~as.factor(condition), data=TR_user_summary)
summary(a)
TukeyHSD(a)

## pr low performing arms sampled
prLPO_actual=roundsData_with_optimal_xtreme3 %>%
  filter(Rounds<21) %>% 
  filter(picks!=1) %>% 
  group_by(usercode, condition) %>% 
  summarise(prLPO=n()/20)
prLPO_actual %>%
  group_by(condition) %>% 
  summarise(mean(prLPO))

prLPO_optimal=roundsData_with_optimal_xtreme3 %>%
  filter(Rounds<21) %>% 
  filter(optimal_picks!=1) %>% 
  group_by(usercode, condition) %>% 
  summarise(prLPO=n()/20)
prLPO_optimal %>%
  group_by(condition) %>% 
  summarise(mean(prLPO))

a=aov(prLPO~as.factor(condition), data=prLPO_actual)
summary(a)
TukeyHSD(a)

prLPO_actual=roundsData_with_optimal_xtreme3 %>%
  filter(picks!=1) %>% 
  group_by(usercode, condition) %>% 
  summarise(prLPO=n()/mean(condition))
prLPO_actual %>%
  group_by(condition) %>% 
  summarise(mean(prLPO))
